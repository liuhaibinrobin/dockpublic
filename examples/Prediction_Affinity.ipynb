{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23142276",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d635b-ade2-4687-b9f3-8a949b264706",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "60c25b64-72b5-43ac-81bb-d8881a32cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_name = \"6scm\" # f'{pdb_name}.pdb' file in the inputs folder will be used.\n",
    "target_name = \"SOS1\"  # \"target\" in the .csv file\n",
    "csv_name = \"all_middle.test.csv\"\n",
    "\n",
    "given_pocket = 0\n",
    "#given_pocket = \"pocket_8\" # or int 0\n",
    "\n",
    "input_path = \"./inputs\" # for .pdb files \n",
    "base_pre = f\"./AFFINITY\" # for results\n",
    "\n",
    "conf_by_chosen = True\n",
    "# if false and \"given_pocket\" is 0, only the conformations relating to the given_pocket will be generated.\n",
    "\n",
    "distinguish_by_timestamp = True \n",
    "# if true, the output folder name will be suffiexed with a timestamp \n",
    "\n",
    "\n",
    "p2rank = \"bash ./p2rank_2.3/prank\" # p2rank file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a8d0a8c-f651-4fee-aa43-a1bb3ccd8aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'all_middle.test.csv',\n",
       " 'all_middle.train.csv',\n",
       " 'all_ndcg.test.csv',\n",
       " 'all_ndcg.train.csv',\n",
       " 'all_pair.test.csv',\n",
       " 'all_pair.train.csv',\n",
       " 'all_top.test.csv',\n",
       " 'all_top.train.csv']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_label_data = \"../../sar-3d-pharam/data/label_data/\"\n",
    "path_data_folder = \"SOS1 HPK1\" # or \"\" if the .csv file is placed in label_data folder\n",
    "\n",
    "\n",
    "    # label_data*\n",
    "    # - HPK1 SOS1*\n",
    "    #     - all_middle.test.csv\n",
    "    #     - all_middle.train.csv\n",
    "    #     - ...\n",
    "    # - PRTM5*\n",
    "    #     - all_middle.test.csv\n",
    "    #     - all_middle.train.csv\n",
    "    #     - ...\n",
    "    # - all_middle.test.csv\n",
    "    # - all_middle.train.csv\n",
    "    # - ...\n",
    "\n",
    "path_data = path_label_data + path_data_folder\n",
    "import os\n",
    "os.listdir(path_data)\n",
    "    # You should see something like this:\n",
    "    #   ['all_middle.test.csv',\n",
    "    #    'all_middle.train.csv',\n",
    "    #    ...\n",
    "    # The SMILES in the 'all_middle.text.csv' file will be used ："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09ed50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_name = target_name.replace(\"_\",\"\")\n",
    "tankbind_src_folder_path = \"../tankbind/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7e20fba-c100-4c11-a825-ccca746d414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS1'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6b7e3127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timetag = time.strftime(\"%m%d%H%M\")\n",
    "\n",
    "if distinguish_by_timestamp:\n",
    "    pre = f\"{base_pre}/{cp_name}-{pdb_name}-{timetag}\"\n",
    "else:\n",
    "    pre = f\"{base_pre}/{cp_name}-{pdb_name}\"\n",
    "    \n",
    "os.system(f\"mkdir -p {pre}\")\n",
    "os.system(f\"rm -rf {pre}/sdfs\")\n",
    "os.system(f\"mkdir -p {pre}/sdfs\")\n",
    "os.system(f\"rm -rf {pre}/PDBs\")\n",
    "os.system(f\"mkdir -p {pre}/PDBs\")\n",
    "os.system(f\"rm -rf {pre}/p2rank\")\n",
    "os.system(f\"mkdir -p {pre}/p2rank\")\n",
    "\n",
    "proteinName = pdb_name\n",
    "proteinFile = f\"{pre}/{proteinName}.pdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb78b71",
   "metadata": {},
   "source": [
    "# get protein feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c7594d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_utils import get_protein_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6acf4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "from feature_utils import get_clean_res_list\n",
    "parser = PDBParser(QUIET=True)\n",
    "protein_dict = {}\n",
    "proteinName = pdb_name\n",
    "proteinFile = f\"./inputs/{pdb_name}.pdb\"\n",
    "s = parser.get_structure(\"example\", proteinFile)\n",
    "res_list = list(s.get_residues())\n",
    "clean_res_list = get_clean_res_list(res_list, ensure_ca_exist=True)\n",
    "protein_dict[proteinName] = get_protein_feature(clean_res_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ef2ed",
   "metadata": {},
   "source": [
    "# p2rank to segment the protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "efdf01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = f\"{pre}/protein_list.ds\"\n",
    "with open(ds, \"w\") as out:\n",
    "    out.write(f\"../../{input_path}/{pdb_name}.pdb\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2054fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      " P2Rank 2.3\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "predicting pockets for proteins from dataset [protein_list.ds]\n",
      "processing [6scm.pdb] (1/1)\n",
      "predicting pockets finished in 0 hours 0 minutes 11.957 seconds\n",
      "results saved to directory [/home/jovyan/TankBind/examples/AFFINITY/SOS1-6scm-07260945/p2rank]\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      " finished successfully in 0 hours 0 minutes 12.817 seconds\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"{p2rank} predict {ds} -o {pre}/p2rank -threads 1\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ac1eb38-81b1-4d22-86d1-af13be03f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(f'{path_data}/{csv_name}')\n",
    "d = d[d[\"target\"]==target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d531aa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:00<00:00, 302.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_name</th>\n",
       "      <th>compound_name</th>\n",
       "      <th>smiles</th>\n",
       "      <th>pocket_name</th>\n",
       "      <th>pocket_com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...</td>\n",
       "      <td>pocket_1</td>\n",
       "      <td>8.709,-24.923,-34.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...</td>\n",
       "      <td>pocket_2</td>\n",
       "      <td>14.982,-43.708,-30.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...</td>\n",
       "      <td>pocket_3</td>\n",
       "      <td>4.658,-7.672,-15.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...</td>\n",
       "      <td>pocket_4</td>\n",
       "      <td>1.534,-35.549,-43.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...</td>\n",
       "      <td>pocket_5</td>\n",
       "      <td>7.982,19.069,-15.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...</td>\n",
       "      <td>pocket_5</td>\n",
       "      <td>7.982,19.069,-15.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...</td>\n",
       "      <td>pocket_6</td>\n",
       "      <td>-1.262,-16.002,-29.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...</td>\n",
       "      <td>pocket_7</td>\n",
       "      <td>3.006,3.753,-22.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...</td>\n",
       "      <td>pocket_8</td>\n",
       "      <td>15.256,-6.178,-31.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>6scm</td>\n",
       "      <td></td>\n",
       "      <td>C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...</td>\n",
       "      <td>pocket_9</td>\n",
       "      <td>-5.474,-33.348,-16.235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2115 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     protein_name compound_name  \\\n",
       "0            6scm                 \n",
       "1            6scm                 \n",
       "2            6scm                 \n",
       "3            6scm                 \n",
       "4            6scm                 \n",
       "...           ...           ...   \n",
       "2110         6scm                 \n",
       "2111         6scm                 \n",
       "2112         6scm                 \n",
       "2113         6scm                 \n",
       "2114         6scm                 \n",
       "\n",
       "                                                 smiles pocket_name  \\\n",
       "0     CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...    pocket_1   \n",
       "1     CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...    pocket_2   \n",
       "2     CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...    pocket_3   \n",
       "3     CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...    pocket_4   \n",
       "4     CN1CCN(c2ccc(Nc3ncc(-c4ccnc5[nH]ccc45)c4cc[nH]...    pocket_5   \n",
       "...                                                 ...         ...   \n",
       "2110  C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...    pocket_5   \n",
       "2111  C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...    pocket_6   \n",
       "2112  C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...    pocket_7   \n",
       "2113  C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...    pocket_8   \n",
       "2114  C[C@@H](NC(=O)c1cc(N2CCC(C)(O)C2)nc2cc[nH]c12)...    pocket_9   \n",
       "\n",
       "                  pocket_com  \n",
       "0      8.709,-24.923,-34.936  \n",
       "1     14.982,-43.708,-30.367  \n",
       "2       4.658,-7.672,-15.484  \n",
       "3      1.534,-35.549,-43.763  \n",
       "4       7.982,19.069,-15.421  \n",
       "...                      ...  \n",
       "2110    7.982,19.069,-15.421  \n",
       "2111   -1.262,-16.002,-29.16  \n",
       "2112     3.006,3.753,-22.598  \n",
       "2113   15.256,-6.178,-31.047  \n",
       "2114  -5.474,-33.348,-16.235  \n",
       "\n",
       "[2115 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = []\n",
    "for i, line in tqdm(d.iterrows(), total=d.shape[0]):\n",
    "    smiles = line['smiles']\n",
    "    compound_name = \"\"\n",
    "    protein_name = proteinName\n",
    "    # use protein center as the pocket center.\n",
    "#    com = \",\".join([str(a.round(3)) for a in protein_dict[proteinName][0].mean(axis=0).numpy()])\n",
    " #   info.append([protein_name, compound_name, smiles, \"protein_center\", com])\n",
    "    # since WDR is actually small enough, and we are interested in finding a ligand binds to the central cavity.\n",
    "    # the block centered at the centroid of the protein is enough.\n",
    "    # we don't need additional p2rank predicted centers.\n",
    "    if True:\n",
    "        p2rankFile = f\"{pre}/p2rank/{proteinName}.pdb_predictions.csv\"\n",
    "        pocket = pd.read_csv(p2rankFile)\n",
    "        pocket.columns = pocket.columns.str.strip()\n",
    "        pocket_coms = pocket[['center_x', 'center_y', 'center_z']].values\n",
    "        for ith_pocket, com in enumerate(pocket_coms):\n",
    "            com = \",\".join([str(a.round(3)) for a in com])\n",
    "            info.append([protein_name, compound_name, smiles, f\"pocket_{ith_pocket+1}\", com])\n",
    "info = pd.DataFrame(info, columns=['protein_name', 'compound_name', 'smiles', 'pocket_name', 'pocket_com'])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d21cf",
   "metadata": {},
   "source": [
    "# construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a072075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aff848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "from utils import construct_data_from_graph_gvp\n",
    "import rdkit.Chem as Chem    # conda install rdkit -c rdkit if import failure.\n",
    "from feature_utils import extract_torchdrug_feature_from_mol, get_canonical_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac200ce2-756d-4884-8b08-777e775578d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "savelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3883313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, proteinMode=0, compoundMode=1,\n",
    "                pocket_radius=20, shake_nodes=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        print(self.processed_paths)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "        #self.printflag = True\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt', 'protein.pt']\n",
    "\n",
    "    def process(self):\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        smiles = line['smiles']\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if type(pocket_com) == str else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line['use_whole_protein'] if \"use_whole_protein\" in line.index else False\n",
    "\n",
    "        protein_name = line['protein_name']\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = self.protein_dict[protein_name]\n",
    "\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            smiles = get_canonical_smiles(smiles)\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            mol.Compute2DCoords()\n",
    "                \n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)\n",
    "        except:\n",
    "            print(\"something wrong with \", smiles, \"to prevent this stops our screening, we repalce it with a placeholder smiles 'CCC'\")\n",
    "            smiles = 'CCC'\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            mol.Compute2DCoords()\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)\n",
    "        # y is distance map, instead of contact map.\n",
    "        data, input_node_list, keepNode = construct_data_from_graph_gvp(protein_node_xyz, protein_seq, protein_node_s, \n",
    "                              protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "                              coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "                              pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "                              use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode)\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f329c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './AFFINITY/SOS1-6scm-07260945/dataset/': No such file or directory\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AFFINITY/SOS1-6scm-07260945/dataset/processed/data.pt', 'AFFINITY/SOS1-6scm-07260945/dataset/processed/protein.pt']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"{pre}/dataset/\"\n",
    "os.system(f\"rm -r {dataset_path}\")\n",
    "os.system(f\"mkdir -p {dataset_path}\")\n",
    "dataset = MyDataset_VS(dataset_path, data=info, protein_dict=protein_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f9c40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm    # pip install tqdm if fails.\n",
    "from model import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814e362",
   "metadata": {},
   "source": [
    "# take about 2 minutes to screen 10,000 drug candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f66a00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:46:05   5 stack, readout2, pred dis map add self attention and GVP embed, compound model GIN\n",
      "Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [00:25<00:00, 16.48it/s]\n"
     ]
    }
   ],
   "source": [
    "bias_list = []\n",
    "batched_energy_list = []\n",
    "\n",
    "batch_size = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device= 'cpu'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = get_model(0, logging, device)\n",
    "# modelFile = \"../saved_models/re_dock.pt\"\n",
    "# self-dock model\n",
    "modelFile = \"../saved_models/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=8)\n",
    "affinity_pred_list = []\n",
    "y_pred_list = []\n",
    "for data in tqdm(data_loader):\n",
    "    data = data.to(device)\n",
    "    if not use_related:\n",
    "        y_pred, affinity_pred = model(data)\n",
    "        affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "    else:\n",
    "        y_pred, affinity_pred, SX_0, SX_1 = model(data)\n",
    "        affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "        bias_list.append(SX_0.detach().cpu())\n",
    "        batched_energy_list.append(SX_1.detach().cpu())\n",
    "    if False:\n",
    "        # we don't need to save the predicted distance map in HTVS setting.\n",
    "        for i in range(data.y_batch.max() + 1):\n",
    "            y_pred_list.append((y_pred[data['y_batch'] == i]).detach().cpu())\n",
    "affinity_pred_list = torch.cat(affinity_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "507d77f2-e586-4ea6-9dad-05f52b2879ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dataset.data\n",
    "info['affinity'] = affinity_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "683ebef0-194e-4b73-95b8-ed7b300fef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv(f\"{pre}/TBAff_{target_name}_{pdb_name}_All.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a00d7238-bb63-4db4-9a8d-f515e0cbdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if given_pocket:\n",
    "    info_given_pocket = info[info[\"pocket_name\"]==given_pocket]\n",
    "    info_given_pocket.to_csv(f\"{pre}/TBAff_{target_name}_{pdb_name}_Given_{given_pocket}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eeb24d35-94d7-42c5-8146-04c125a05ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['affinity'].agg('idxmax')].reset_index()\n",
    "chosen.to_csv(f\"{pre}/TBAff_{target_name}_{pdb_name}_TBChosen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f3a8c094-7684-43cd-ab43-6a5bf5492064",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv(f\"{pre}/result_info.csv\")\n",
    "if given_pocket:\n",
    "    info_right_pocket = info[info[\"pocket_name\"]==right_pocket]\n",
    "    info_right_pocket.to_csv(f\"{pre}/result_info_rightpocket.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac562f1-cd47-462b-907d-cd7d81f5e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736b5a32-e25b-494b-a3e6-e8c97c60b964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Related-Atoms Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1dfcc096-ee39-4c51-8aed-afe7b9f37442",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_related = False\n",
    "if use_related:\n",
    "    energy_list = []\n",
    "    for _batch in batched_energy_list:\n",
    "        for item in _batch:\n",
    "            energy_list.append(item)\n",
    "            \n",
    "    related_atoms_list = []\n",
    "    num_atoms_list = []\n",
    "    for p in info.iterrows():\n",
    "        sm = p[1][\"smiles\"]\n",
    "        #print(sm)\n",
    "        smiles = get_canonical_smiles(sm)\n",
    "        #print(smiles)\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        related = []\n",
    "        for _atom in mol.GetAtoms():\n",
    "            if _atom.GetAtomicNum() in [7, 8]:\n",
    "                related.append(_atom.GetIdx())\n",
    "        related_atoms_list.append(related)\n",
    "        num_atoms_list.append(mol.GetNumHeavyAtoms())\n",
    "    \n",
    "    colsum_energy_list = [i.sum(axis=0) for i in energy_list]\n",
    "    related_energy_list = [colsum_energy_list[i][related_atoms_list[i]].sum() for i in range(len(colsum_energy_list))]\n",
    "    total_energy_list = [i.sum() for i in energy_list]\n",
    "\n",
    "    related_energy_tensor = torch.tensor(related_energy_list)\n",
    "    total_energy_tensor = torch.tensor(total_energy_list)\n",
    "    nonrelated_energy_tensor = total_energy_tensor - related_energy_tensor\n",
    "\n",
    "    bias = bias_list[0]\n",
    "    outleaky = torch.nn.LeakyReLU()\n",
    "\n",
    "    related_affinity = outleaky(bias + related_energy_tensor)\n",
    "    nonrelated_affinity = outleaky(bias + nonrelated_energy_tensor)\n",
    "    \n",
    "    info['related_affinity'] = related_affinity\n",
    "    info['nonrelated_affinity'] = nonrelated_affinity\n",
    "    \n",
    "    related_chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['related_affinity'].agg('idxmax')].reset_index()\n",
    "    nonrelated_chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['nonrelated_affinity'].agg('idxmax')].reset_index()\n",
    "    related_chosen.to_csv(f\"{pre}/result_chosen_related.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56077dc-6659-4662-be95-4ccfed2c1d91",
   "metadata": {},
   "source": [
    "# 以下暂时不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20328763",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m one_data \u001b[38;5;241m=\u001b[39m dataset[idx]\n\u001b[1;32m      8\u001b[0m data_with_batch_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(DataLoader(dataset[idx:idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      9\u001b[0m                          follow_batch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound_pair\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 10\u001b[0m y_pred, affinity_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_with_batch_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m coords \u001b[38;5;241m=\u001b[39m one_data\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m protein_nodes_xyz \u001b[38;5;241m=\u001b[39m one_data\u001b[38;5;241m.\u001b[39mnode_xyz\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jovyan/TankBind/examples/../tankbind/model.py:349\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m    350\u001b[0m     mylogs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== IMODEL START======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys:\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jovyan/TankBind/examples/../tankbind/model.py:89\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, h_V, edge_index, h_E, seq)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node_in_dim \u001b[38;5;241m=\u001b[39m (node_in_dim[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m, node_in_dim[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_v \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     83\u001b[0m     LayerNorm(node_in_dim),\n\u001b[1;32m     84\u001b[0m     GVP(node_in_dim, node_h_dim, activations\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_e \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     87\u001b[0m     LayerNorm(edge_in_dim),\n\u001b[1;32m     88\u001b[0m     GVP(edge_in_dim, edge_h_dim, activations\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m     92\u001b[0m         GVPConvLayer(node_h_dim, edge_h_dim, drop_rate\u001b[38;5;241m=\u001b[39mdrop_rate) \n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers))\n\u001b[1;32m     95\u001b[0m ns, _ \u001b[38;5;241m=\u001b[39m node_h_dim\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "# pick one with affinity greater than 7.\n",
    "chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['affinity'].agg('idxmax')].reset_index()\n",
    "chosen = chosen.query(\"affinity > 7\").reset_index(drop=True)\n",
    "line = chosen.iloc[0]\n",
    "idx = line['index']\n",
    "one_data = dataset[idx]\n",
    "data_with_batch_info = next(iter(DataLoader(dataset[idx:idx+1], batch_size=1, \n",
    "                         follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=1)))\n",
    "y_pred, affinity_pred = model(data_with_batch_info)\n",
    "\n",
    "coords = one_data.coords.to(device)\n",
    "protein_nodes_xyz = one_data.node_xyz.to(device)\n",
    "n_compound = coords.shape[0]\n",
    "n_protein = protein_nodes_xyz.shape[0]\n",
    "y_pred = y_pred.reshape(n_protein, n_compound).to(device).detach()\n",
    "y = one_data.dis_map.reshape(n_protein, n_compound).to(device)\n",
    "compound_pair_dis_constraint = torch.cdist(coords, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0100c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = line['smiles']\n",
    "print(smiles)\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "mol.Compute2DCoords()\n",
    "LAS_distance_constraint_mask = get_LAS_distance_constraint_mask(mol).bool()\n",
    "info = get_info_pred_distance(coords, y_pred, protein_nodes_xyz, compound_pair_dis_constraint, \n",
    "                              LAS_distance_constraint_mask=LAS_distance_constraint_mask,\n",
    "                              n_repeat=1, show_progress=False)\n",
    "toFile = f'{base_pre}/one_tankbind.sdf'\n",
    "new_coords = info.sort_values(\"loss\")['coords'].iloc[0].astype(np.double)\n",
    "write_with_new_coords(mol, new_coords, toFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c604bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview   # conda install nglview -c conda-forge if import failure\n",
    "\n",
    "proteinName = \"6dlo\"\n",
    "proteinFile = f\"{base_pre}/{proteinName}.pdb\"\n",
    "view = nglview.show_file(nglview.FileStructure(proteinFile), default=False)\n",
    "view.add_representation('cartoon', selection='protein', color='white')\n",
    "\n",
    "predictedFile = f'{base_pre}/one_tankbind.sdf'\n",
    "rdkit = view.add_component(nglview.FileStructure(predictedFile), default=False)\n",
    "rdkit.add_ball_and_stick(color='red')\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.render_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view._display_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b68e83-0b11-4ba3-b624-bd5ec29241ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357a8e7-ae7c-4b45-b311-7dfef6fd225c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d894a43-d13c-420e-9f95-1c3170dffe13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f287a6-da53-4eef-977e-9ede12ca0f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tankbind_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
