{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34c67c03-cee8-4dcc-bd80-3ebbece6a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from Bio.PDB.PDBList import PDBList   # pip install biopython if import failure\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from IPython import embed\n",
    "import argparse\n",
    "from Bio.PDB import PDBParser\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, InMemoryDataset\n",
    "from torch_geometric.data import HeteroData, Data\n",
    "import rdkit.Chem as Chem    # conda install rdkit -c rdkit if import failure.\n",
    "import logging\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm    # pip install tqdm if fails.\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d25e3f2a-dff3-418f-adc3-b560bf265aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###csv顺序：test -> valid -> train\n",
    "a1 = pd.read_csv('/home/jovyan/TankBind/examples/data/PRMT5/test.csv')\n",
    "a2 = pd.read_csv('/home/jovyan/TankBind/examples/data/PRMT5/valid.csv')\n",
    "a3 = pd.read_csv('/home/jovyan/TankBind/examples/data/PRMT5/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86169072-153e-411b-af2b-d7ba50b6ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame()\n",
    "s['smiles'] = pd.concat((a1['smiles'],a2['smiles'],a3['smiles']))\n",
    "s['md5'] = s.index\n",
    "s.to_csv('PRMT5-ID-SMILES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6a8f2b5-2796-44dd-bd1c-a7d003652fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "random.seed(seed)\n",
    "# 没有使用GPU的时候设置的固定生成的随机数\n",
    "np.random.seed(seed)\n",
    "# 为CPU设置种子用于生成随机数，以使得结果是确定的\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed()为当前GPU设置随机种子\n",
    "torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37ff7437-950f-4096-a814-a3844c79e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2103, -0.3908,  0.2350,  0.6653,  0.3528]])\n",
      "tensor([[ 0.9728, -0.0386, -0.8861, -0.4709, -0.4269]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.randn(1,5))\n",
    "print(torch.randn(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d6b7f7-d345-4160-aac5-c0028b635f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_name = 'SOS1'\n",
    "data_path = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ca51478-4bcd-4072-9fef-5c2fba7f710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'embedding/{cp_name}/{cp_name}_z_dic.pickle', 'rb') as f:\n",
    "        z1_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98d34c3a-0e42-43fb-8ba6-a63892592d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C[C@@H](NC(=O)c1cc(N2CCN(C(=O)C3CC3)CC2)nc2cc[nH]c12)c1cccc(C(F)F)c1F': tensor([[[ 2.3399, -1.4879,  4.8747,  ...,  2.3590,  1.1545,  8.3941],\n",
       "          [ 1.8831, -1.2948,  4.9656,  ...,  2.3852,  1.1021,  9.0993],\n",
       "          [ 1.7584, -1.0555,  4.5793,  ...,  2.3966,  1.3536,  9.0791],\n",
       "          ...,\n",
       "          [ 2.6375, -1.8197,  4.7907,  ...,  1.8962,  0.5390,  8.0581],\n",
       "          [ 1.9908, -1.4390,  4.4469,  ...,  2.6538,  0.9489,  9.1351],\n",
       "          [ 2.5197, -1.6800,  4.2525,  ...,  2.6062,  0.7709,  8.5632]],\n",
       " \n",
       "         [[ 2.1851, -1.1090,  4.6696,  ...,  1.8702,  2.3108,  7.6009],\n",
       "          [ 1.9387, -0.9416,  4.8662,  ...,  1.8577,  2.7454,  8.0793],\n",
       "          [ 1.6759, -0.9517,  4.7765,  ...,  2.0617,  2.7283,  8.3647],\n",
       "          ...,\n",
       "          [ 3.0993, -1.9774,  4.6330,  ...,  1.9675,  2.4680,  6.7285],\n",
       "          [ 2.5956, -1.4266,  4.3800,  ...,  1.8511,  2.3295,  8.0771],\n",
       "          [ 2.9268, -1.5961,  4.1313,  ...,  1.8882,  2.2146,  7.9176]],\n",
       " \n",
       "         [[ 2.3316, -1.7639,  5.4850,  ...,  1.7563,  1.2861,  7.8664],\n",
       "          [ 2.1933, -1.5838,  5.4901,  ...,  1.9627,  1.2180,  8.0513],\n",
       "          [ 2.4525, -1.3615,  5.3276,  ...,  2.1063,  1.2312,  8.3883],\n",
       "          ...,\n",
       "          [ 2.7883, -1.9462,  5.1047,  ...,  1.3007,  1.3221,  7.9054],\n",
       "          [ 2.2819, -1.6218,  5.8392,  ...,  2.1428,  1.4330,  8.6477],\n",
       "          [ 2.5094, -1.7340,  4.9565,  ...,  1.8828,  1.4829,  8.4090]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "          [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "          [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "          ...,\n",
       "          [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "          [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "          [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]],\n",
       " \n",
       "         [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "          [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "          [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "          ...,\n",
       "          [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "          [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "          [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]],\n",
       " \n",
       "         [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "          [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "          [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "          ...,\n",
       "          [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "          [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "          [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d1d2a6b-455c-4566-a628-b3254137e7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2693, -1.4062,  4.0642,  ...,  2.3939,  1.4587,  7.8709],\n",
       "         [ 2.0383, -1.2953,  3.9155,  ...,  2.2216,  1.7196,  8.8879],\n",
       "         [ 1.9888, -1.2847,  3.9210,  ...,  2.2868,  1.7374,  8.9687],\n",
       "         ...,\n",
       "         [ 2.2467, -1.2667,  3.7199,  ...,  2.5209,  1.2137,  9.1198],\n",
       "         [ 2.0149, -1.2938,  3.8197,  ...,  2.3803,  1.6675,  9.1490],\n",
       "         [ 1.9888, -1.2847,  3.9210,  ...,  2.2868,  1.7374,  8.9687]],\n",
       "\n",
       "        [[ 1.5851, -2.0898,  4.3281,  ...,  1.7419,  2.8498,  8.4402],\n",
       "         [ 1.2736, -1.7670,  4.4192,  ...,  1.8751,  3.0511,  8.9658],\n",
       "         [ 1.2783, -1.6859,  4.4080,  ...,  1.9093,  3.0217,  9.0674],\n",
       "         ...,\n",
       "         [ 2.2689, -1.4772,  4.0558,  ...,  1.8140,  2.4733,  8.7409],\n",
       "         [ 1.4350, -1.4896,  4.3914,  ...,  1.9122,  2.8869,  9.1918],\n",
       "         [ 1.2783, -1.6859,  4.4080,  ...,  1.9093,  3.0217,  9.0674]],\n",
       "\n",
       "        [[ 2.5383, -1.9612,  4.8696,  ...,  0.8452,  1.6685,  8.1829],\n",
       "         [ 2.0598, -1.7000,  5.1757,  ...,  1.1813,  1.9837,  8.8181],\n",
       "         [ 2.0805, -1.7189,  5.2308,  ...,  1.2205,  1.9722,  8.8907],\n",
       "         ...,\n",
       "         [ 2.3677, -1.9993,  5.2168,  ...,  1.5768,  1.4565,  8.4699],\n",
       "         [ 2.0339, -1.7810,  5.2649,  ...,  1.3450,  2.0846,  8.9635],\n",
       "         [ 2.0805, -1.7189,  5.2308,  ...,  1.2205,  1.9722,  8.8907]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.7484, -0.1538,  1.3364,  ..., -1.0212, -0.4438,  2.0898],\n",
       "         [ 1.5086, -0.7630,  1.1686,  ..., -1.0910, -0.6399,  2.3332],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154],\n",
       "         ...,\n",
       "         [ 1.1614, -1.0403,  0.7724,  ..., -1.0973,  0.1178,  1.9697],\n",
       "         [ 1.0553, -1.4688,  0.8987,  ..., -1.2818, -0.1103,  2.5938],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154]],\n",
       "\n",
       "        [[ 1.7484, -0.1538,  1.3364,  ..., -1.0212, -0.4438,  2.0898],\n",
       "         [ 1.5086, -0.7630,  1.1686,  ..., -1.0910, -0.6399,  2.3332],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154],\n",
       "         ...,\n",
       "         [ 1.1614, -1.0403,  0.7724,  ..., -1.0973,  0.1178,  1.9697],\n",
       "         [ 1.0553, -1.4688,  0.8987,  ..., -1.2818, -0.1103,  2.5938],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154]],\n",
       "\n",
       "        [[ 1.7484, -0.1538,  1.3364,  ..., -1.0212, -0.4438,  2.0898],\n",
       "         [ 1.5086, -0.7630,  1.1686,  ..., -1.0910, -0.6399,  2.3332],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154],\n",
       "         ...,\n",
       "         [ 1.1614, -1.0403,  0.7724,  ..., -1.0973,  0.1178,  1.9697],\n",
       "         [ 1.0553, -1.4688,  0.8987,  ..., -1.2818, -0.1103,  2.5938],\n",
       "         [ 1.3326, -1.1569,  1.1041,  ..., -1.0412, -0.5902,  2.6154]]],\n",
       "       device='cuda:1', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('gasegasdg.pkl', 'rb') as f:\n",
    "    z_yz_dic = pickle.load(f)\n",
    "z_yz_dic[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7684b7c2-b70d-462e-a225-e729d98d1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gasegasdg-4.pkl', 'rb') as f:\n",
    "    z_yzs_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b88d77a-ff4b-4081-aa17-61dd86317663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.3399, -1.4879,  4.8747,  ...,  2.3590,  1.1545,  8.3941],\n",
       "         [ 1.8831, -1.2948,  4.9656,  ...,  2.3852,  1.1021,  9.0993],\n",
       "         [ 1.7584, -1.0555,  4.5793,  ...,  2.3966,  1.3536,  9.0791],\n",
       "         ...,\n",
       "         [ 2.6375, -1.8197,  4.7907,  ...,  1.8962,  0.5390,  8.0581],\n",
       "         [ 1.9908, -1.4390,  4.4469,  ...,  2.6538,  0.9489,  9.1351],\n",
       "         [ 2.5197, -1.6800,  4.2525,  ...,  2.6062,  0.7709,  8.5632]],\n",
       "\n",
       "        [[ 2.1851, -1.1090,  4.6696,  ...,  1.8702,  2.3108,  7.6009],\n",
       "         [ 1.9387, -0.9416,  4.8662,  ...,  1.8577,  2.7454,  8.0793],\n",
       "         [ 1.6759, -0.9517,  4.7765,  ...,  2.0617,  2.7283,  8.3647],\n",
       "         ...,\n",
       "         [ 3.0993, -1.9774,  4.6330,  ...,  1.9675,  2.4680,  6.7285],\n",
       "         [ 2.5956, -1.4266,  4.3800,  ...,  1.8511,  2.3295,  8.0771],\n",
       "         [ 2.9268, -1.5961,  4.1313,  ...,  1.8882,  2.2146,  7.9176]],\n",
       "\n",
       "        [[ 2.3316, -1.7639,  5.4850,  ...,  1.7563,  1.2861,  7.8664],\n",
       "         [ 2.1933, -1.5838,  5.4901,  ...,  1.9627,  1.2180,  8.0513],\n",
       "         [ 2.4525, -1.3615,  5.3276,  ...,  2.1063,  1.2312,  8.3883],\n",
       "         ...,\n",
       "         [ 2.7883, -1.9462,  5.1047,  ...,  1.3007,  1.3221,  7.9054],\n",
       "         [ 2.2819, -1.6218,  5.8392,  ...,  2.1428,  1.4330,  8.6477],\n",
       "         [ 2.5094, -1.7340,  4.9565,  ...,  1.8828,  1.4829,  8.4090]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "         [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "         [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "         ...,\n",
       "         [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "         [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "         [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]],\n",
       "\n",
       "        [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "         [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "         [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "         ...,\n",
       "         [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "         [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "         [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]],\n",
       "\n",
       "        [[ 1.1992, -0.6159,  1.1669,  ..., -1.3054, -0.4410,  2.4121],\n",
       "         [ 1.0664, -0.6968,  0.4307,  ..., -1.5709,  0.4509,  2.2068],\n",
       "         [ 0.7243, -0.8598,  0.2483,  ..., -1.8092,  0.3442,  1.6220],\n",
       "         ...,\n",
       "         [ 1.1659,  0.1398,  1.2957,  ..., -0.8626, -0.1436,  1.7706],\n",
       "         [ 1.0160, -0.5345,  0.9206,  ..., -1.4186,  0.2974,  2.0887],\n",
       "         [ 0.8760, -0.6609,  0.6698,  ..., -1.6058,  0.9217,  1.7998]]],\n",
       "       device='cuda:1', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_yzs_dic[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49554d7-44a4-48f6-9a2a-d2ecb5681b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'embedding_1/{cp_name}/{cp_name}_z_dic.pickle', 'rb') as f:\n",
    "        z1_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d83367-0d1c-4a16-9595-1a5d4d2f46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv(f'{data_path}/{cp_name}/train.csv')\n",
    "df_tr['smiles'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf75836-77dc-4ecb-b5aa-fa92f37466a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z1_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mz1_dic\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC[C@@H](NC(=O)c1cc(N2CCN(C(=O)C3CC3)CC2)nc2cc[nH]c12)c1cccc(C(F)F)c1F\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshpae\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z1_dic' is not defined"
     ]
    }
   ],
   "source": [
    "z1_dic['C[C@@H](NC(=O)c1cc(N2CCN(C(=O)C3CC3)CC2)nc2cc[nH]c12)c1cccc(C(F)F)c1F'].shpae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d02f26f-7cf6-4854-9327-517a00d700ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0132, -2.1145,  2.8687,  ...,  1.6953,  1.4559,  5.8407],\n",
       "        [ 2.9870, -2.3818,  2.9469,  ...,  1.8012,  1.6740,  6.4748],\n",
       "        [ 2.9428, -2.5652,  2.8479,  ...,  1.7798,  1.7830,  6.7796],\n",
       "        ...,\n",
       "        [ 2.7734, -2.3569,  2.9392,  ...,  1.4895,  1.5314,  6.3214],\n",
       "        [ 3.2896, -2.5458,  3.5529,  ...,  2.1343,  2.1536,  7.2697],\n",
       "        [ 3.0626, -2.4423,  3.2966,  ...,  1.8032,  1.7171,  6.8216]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2_dic['Cc1nc(NC(C)c2cccc(C(F)(F)C(C)(C)O)c2F)c2cn(C3(C)CC3)c(=O)c(F)c2n1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc8e79c-a202-4497-90dc-9fb120245774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'embed/{cp_name}/{cp_name}_z_mask_dic.pickle', 'rb') as f:\n",
    "        z_mask_dic = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61018fa8-add1-4d17-a215-37a8b17e31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'embedding/{cp_name}/{cp_name}_sum_embedding_dic.pickle', 'rb') as f1:\n",
    "        SOS1_sum_embedding_dic = pickle.load(f1)\n",
    "with open(f'embedding/{cp_name}/{cp_name}_z_dic.pickle', 'rb') as f:\n",
    "        z_dic = pickle.load(f)\n",
    "df_tr = pd.read_csv(f'{data_path}/{cp_name}/train.csv')\n",
    "df_te = pd.read_csv(f'{data_path}/{cp_name}/test.csv')\n",
    "df_va = pd.read_csv(f'{data_path}/{cp_name}/valid.csv')\n",
    "df_tr['embed'] = df_te['embed'] = df_va['embed'] = ''\n",
    "df_tr['z'] = df_te['z'] = df_va['z'] = ''\n",
    "for index, row in df_tr.iterrows():\n",
    "    row['embed'] = SOS1_sum_embedding_dic[row['smiles']]\n",
    "    row['z'] = z_dic[row['smiles']]\n",
    "    df_tr.iloc[index] = row\n",
    "for index, row in df_te.iterrows():\n",
    "    row['embed'] = SOS1_sum_embedding_dic[row['smiles']]\n",
    "    row['z'] = z_dic[row['smiles']]\n",
    "    df_te.iloc[index] = row\n",
    "for index, row in df_va.iterrows():\n",
    "    row['embed'] = SOS1_sum_embedding_dic[row['smiles']]\n",
    "    row['z'] = z_dic[row['smiles']]\n",
    "    df_va.iloc[index] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "608bceab-ba90-40db-bbcb-13162588a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_tr.loc[:, 'z'].to_numpy()[0]\n",
    "b = df_tr.loc[:, 'z'].to_numpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77ccb2e3-edc6-439c-8846-87a3eec1bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.unsqueeze(a, dim=0)\n",
    "b1 = torch.unsqueeze(b, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8220b14f-a0ed-45b1-946f-7c83938f6bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 34 but got size 35 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 34 but got size 35 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "torch.concat((a1,b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10448ca-45d8-4ad2-9e96-f948fe0a320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7295.5718,  -6179.6108,   7985.6260,  10558.9609,  -3863.0754,\n",
       "          1874.1375,    612.0879,  -5922.7700,  -1991.2085,   3476.6892,\n",
       "          7682.9136,   5522.0137,   6655.0601,   9226.5605,  -2289.0125,\n",
       "          7817.2446,   3434.8013,    216.1904,   5004.5522,   7140.1074,\n",
       "         -9133.6318,   9270.3848,  16789.3164,   3299.7046, -20606.5664,\n",
       "         -7122.0000,  38028.9727,   2258.1685,  -4636.8979,   7467.6230,\n",
       "          1952.0891,  12160.7871,  12557.6816,  -8187.3975,  -3658.1338,\n",
       "         14071.5908,   9626.4844,   4395.8291,  -1401.1707,   4924.4038,\n",
       "          -188.0455,   5632.4868,   4946.7588,    440.8533,   5278.3477,\n",
       "          -161.5130,  19907.0391,   3824.0552,  11751.7500,   4895.6064,\n",
       "         -3015.1365,   2540.9653,   8079.2974,   5214.3828, -19366.1289,\n",
       "         -5080.1797,   5507.0752,   1829.8391,   6824.9844,  -8244.6738,\n",
       "           687.9783,  -4938.0981,   1040.7375,  -9033.2793,  -5148.1650,\n",
       "           393.4572,  -1199.0422,   7579.3418,  -6333.5527,  -6099.5435,\n",
       "         -1935.9459,   9390.0820,   1622.4417,   -384.8581,  -2690.1836,\n",
       "         -9021.3877,  -4643.7954,   2122.3428,   6036.5015,  11175.6104,\n",
       "          8530.5029, -10172.5098,  13297.4072,  -2731.5454,  -5849.2227,\n",
       "          1204.9613, -10124.1113,  -2290.3745,   9738.7764,   7098.2251,\n",
       "          1197.7944,   8250.6074,   4891.7324,   -823.0111,   -833.2410,\n",
       "         13644.4844,  12537.2559,   2467.8994,   9656.9844,  -6127.4907,\n",
       "          4338.4697,   1279.5736,  -5714.4697,  -3411.5627,  -5635.3872,\n",
       "          2431.7520,  15053.1543,  32679.9258,  -8418.2139,  -4180.9697,\n",
       "          -495.3401,   4623.9785,   1859.9805, -56348.3750,  13024.1992,\n",
       "         -2430.2974,  -6595.4023,  -8249.4922,  -4593.4746,   9306.3369,\n",
       "         -1731.0046,   1586.2798,  -2279.9695,     65.7676,  -4106.7324,\n",
       "          3601.3665,   6821.8862,  13389.6367], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array(embed)).to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0ed798b-94c7-4019-a980-84372e296e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBDataset(Dataset):\n",
    "    def __init__(self,root, df_tr=None, df_te=None, df_va=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "        '''\n",
    "        '''\n",
    "        self.compound_name = 'SOS1'\n",
    "        self.trainindx = 0\n",
    "        self.testindx = 0\n",
    "        self.valindx = 0\n",
    "        self.test_df = df_te\n",
    "        self.train_df = df_tr\n",
    "        self.val_df = df_va\n",
    "        self.testindx = len(self.test_df)\n",
    "        self.expected_test_count = len(self.test_df)\n",
    "        self.trainindx = len(self.train_df) +  self.testindx\n",
    "        self.expected_train_count = len(self.train_df)\n",
    "        self.valindx = len(self.val_df) + self.trainindx\n",
    "        self.expected_val_count = len(self.val_df) \n",
    "        super(TBDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        print(self.processed_dir)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_0.pt']\n",
    "    def process(self):\n",
    "        tasks = 'label'\n",
    "        idx_list = []\n",
    "        i = 0\n",
    "        for df in [self.test_df, self.train_df, self.val_df]:\n",
    "            # print(df)\n",
    "            smiles_list = df.loc[:, 'smiles'].tolist() if 'smiles' in set(df.columns) else df.loc[:, 'mol'].tolist() if 'mol' in set(df.columns) else None\n",
    "            assert smiles_list is not None, \"Cannot find the smiles column in the data file\"\n",
    "            assert tasks is not None, \"Cannot determine the target tasks due to unsupported dataset\"\n",
    "            self.ntasks = len(tasks)\n",
    "            labels_list = df.loc[:, tasks]\n",
    "            group_id_list = df.loc[:, 'group']\n",
    "            embed_list = df.loc[:, 'embed']\n",
    "            z_list = df.loc[:, 'z']\n",
    "            \n",
    "            labels_list = labels_list.to_numpy()\n",
    "            group_id_list = group_id_list.to_numpy()\n",
    "            embed_list = embed_list.to_numpy()\n",
    "            z_list = z_list.to_numpy()\n",
    "            group_dic = {}\n",
    "            tmp = 0\n",
    "            for idx in tqdm(range(len(smiles_list))):\n",
    "                embed, label, group_id_str, z = embed_list[idx], labels_list[idx], group_id_list[idx], z_list[idx]\n",
    "                # embed, label, group_id_str = embed_list[idx], labels_list[idx], group_id_list[idx]\n",
    "                data = HeteroData()\n",
    "                data.x = embed\n",
    "                data.x = data.x.reshape(1,128)\n",
    "                data.z = z.view(-1,128)\n",
    "                data.y = torch.from_numpy(np.array(label)).to(torch.double)\n",
    "                data.reverse = 0\n",
    "                data.reverse = torch.tensor([data.reverse],dtype = torch.int64) \n",
    "                group_id = group_dic.get(group_id_str)\n",
    "                if group_id is None:\n",
    "                    group_id = tmp\n",
    "                    group_dic[group_id_str] = tmp\n",
    "                    tmp += 1\n",
    "                data.group_id =  torch.from_numpy(np.array(group_id)).to(torch.double)\n",
    "\n",
    "                torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "                i += 1\n",
    "            idx_list.append(i)\n",
    "\n",
    "            \n",
    "        self.testindx, self.trainindx, self.valindx = idx_list\n",
    "        self.expected_test_count = self.testindx\n",
    "        self.trainindx = len(self.train_df) +  self.testindx\n",
    "        self.expected_train_count = len(self.train_df)\n",
    "        self.valindx = len(self.val_df) + self.trainindx\n",
    "        self.expected_val_count = len(self.val_df)\n",
    "        \n",
    "    def len(self):\n",
    "        return self.expected_test_count + self.expected_train_count \\\n",
    "            + self.expected_val_count\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        data.idx = idx\n",
    "        return  data\n",
    "    def get_idx_split(self):\n",
    "        return self.expected_test_count, \\\n",
    "            self.expected_test_count + self.expected_train_count, \\\n",
    "            self.expected_test_count + self.expected_train_count + self.expected_val_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c99843-55a7-495a-b5f9-ac2c37979a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TBNet, self).__init__()\n",
    "        self.downstream_n_layers = 3\n",
    "        self.lr = 0.0001\n",
    "        self.dropout = 0.15\n",
    "        self.compound_name = 'SOS1'\n",
    "        self.loss_fn = PairwiseLoss()\n",
    "        self.downstream_out = nn.Linear(128, 1)\n",
    "        ffn_layers=[FFN(128, 0.15) for _ in range(3)]\n",
    "        self.layers = nn.ModuleList(ffn_layers)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for ffn_layer in self.layers:\n",
    "            x = ffn_layer(x)\n",
    "        x = self.downstream_out(x)\n",
    "        return x\n",
    "\n",
    "    def my_loss(self, pred, target, groupid):\n",
    "        is_valid = torch.logical_not(torch.isnan(target))\n",
    "        return self.loss_fn(pred[is_valid], target[is_valid], groupid)\n",
    "class PairwiseLoss(nn.Module):\n",
    "    def __init__(self, keep_rate=1., sigmoid_lambda=1.,\n",
    "                 ingrp_thr=0.3, outgrp_thr=9999, eval=False):\n",
    "        super(PairwiseLoss, self).__init__()\n",
    "        self.eval = eval\n",
    "        self.register_buffer('keep_rate', torch.tensor(keep_rate, dtype=torch.float64))\n",
    "        self.register_buffer('sigmoid_lambda', torch.tensor(sigmoid_lambda, dtype=torch.float64))\n",
    "        self.register_buffer('ingrp_thr', torch.tensor(ingrp_thr, dtype=torch.float64))\n",
    "        self.register_buffer('outgrp_thr', torch.tensor(outgrp_thr, dtype=torch.float64))\n",
    "\n",
    "    def forward(self, pred, true, groupid):\n",
    "\n",
    "        \"\"\"\n",
    "        Customized pairwise ranking loss.\n",
    "\n",
    "        \"\"\"\n",
    "        # print('pred',pred)\n",
    "        # print('true',true)\n",
    "        # print('group_id',groupid)\n",
    "        if len(pred.shape) == 1:\n",
    "            pred = pred.unsqueeze(1)\n",
    "        if len(true.shape) == 1:\n",
    "            true = true.unsqueeze(1)\n",
    "        drop_rate = 1 - self.keep_rate\n",
    "        true_tile_row = true.repeat((1, true.shape[0]))\n",
    "        true_tile_col = torch.t(true_tile_row)\n",
    "        assert (true_tile_row.shape == true_tile_col.shape)\n",
    "\n",
    "        groupid_row = groupid.repeat((groupid.shape[0], 1))\n",
    "        # print(groupid_row.shape)\n",
    "        groupid_col = torch.t(groupid_row)\n",
    "\n",
    "        pred_tile_row = pred.repeat((1, pred.shape[0]))\n",
    "        pred_tile_col = torch.t(pred_tile_row)\n",
    "        # diff = (true_tile_row - true_tile_col) / (torch.abs(true_tile_col) + 1e-4)\n",
    "        diff = (true_tile_row - true_tile_col)\n",
    "        # print(diff)\n",
    "        pred_pair = torch.stack([pred_tile_row, pred_tile_col], dim=0)\n",
    "        # print(groupid_row.shape)\n",
    "        # print(groupid_col.shape)\n",
    "        # print(diff.shape)\n",
    "        valid_ind = torch.logical_or(torch.logical_and(groupid_row == groupid_col, diff > self.ingrp_thr),\n",
    "                                     diff > self.outgrp_thr)\n",
    "        # print(\"(valid_ind)\",valid_ind)\n",
    "        pred_pair_valid = pred_pair.masked_select(valid_ind).reshape(2, -1)\n",
    "        pred_pair_diff = pred_pair_valid[0] - pred_pair_valid[1]\n",
    "        # print(pred_pair_diff)\n",
    "        reverse = torch.sum(pred_pair_diff > 0)\n",
    "        ntotal = pred_pair_valid.shape[1] + 1e-8\n",
    "        # print(\"Total valid pairs: {:.3f}, reversed: {:.3f}, reverse ratio: {:.3f}\".format(ntotal, reverse, reverse/ntotal))\n",
    "        if drop_rate > 1e-4:\n",
    "            pred_pair_valid_dropout = torch.nn.functional.dropout(pred_pair_valid[0], drop_rate) * self.keep_rate\n",
    "            pred_pair_valid_ind = torch.logical_or(pred_pair_valid_dropout == pred_pair_valid[0],\n",
    "                                                   pred_pair_valid_dropout != 0.0)\n",
    "\n",
    "            pred_pair_valid = pred_pair_valid.masked_select(pred_pair_valid_ind).reshape(2, -1)\n",
    "\n",
    "        loss = torch.sum(torch.log(1. + torch.exp(self.sigmoid_lambda * (pred_pair_valid[1] - pred_pair_valid[0]))))\n",
    "        \n",
    "        num = pred_pair_valid.shape[1] + 1e-8\n",
    "\n",
    "        loss = torch.div(loss, num)\n",
    "        return loss, reverse/ntotal\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_rate):\n",
    "        super(FFN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.gelu(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f54e10-dbbc-4720-9b7d-af316a1e02f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e54944c-c7df-4241-819a-f7c2ad08ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|██████████| 119/119 [00:04<00:00, 25.87it/s]\n",
      "100%|██████████| 569/569 [00:21<00:00, 26.85it/s]\n",
      "100%|██████████| 191/191 [00:07<00:00, 26.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/SOS1/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = TBDataset(root='data/SOS1',df_tr=df_tr, df_te=df_te, df_va=df_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a204aa42-054a-48c1-9aaf-a9c8a2f20dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  x=[1, 128],\n",
       "  z=[5075, 128],\n",
       "  y=7.4591703,\n",
       "  reverse=[1],\n",
       "  group_id=0.0,\n",
       "  idx=0\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "212c4420-4b96-482f-b0a2-aa001b04fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  x=[1, 128],\n",
       "  z=[4495, 128],\n",
       "  y=7.4936304,\n",
       "  reverse=[1],\n",
       "  group_id=0.0,\n",
       "  idx=1\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3db9f2bd-87ca-4e5d-84c4-df8b695a57ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "te, tr, va = dataset.get_idx_split()\n",
    "dataset_test = dataset[:te]\n",
    "dataset_train = dataset[te:tr]\n",
    "#self.dataset_train= self.dataset_test\n",
    "#self.dataset_val =self.dataset_test\n",
    "dataset_val = dataset[tr:va]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f76a44f-1f09-4b70-8b44-9e45c825f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_tr = DataLoader(dataset_train, batch_size=3, shuffle=False, num_workers=3)\n",
    "data_loader_te = DataLoader(dataset_test, batch_size=10, shuffle=False, num_workers=3)\n",
    "data_loader_va = DataLoader(dataset_val, batch_size=10, shuffle=False, num_workers=3)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "model = TBNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "143fe74b-b25f-4710-9f49-ee4bd98187df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  x=[1, 128],\n",
       "  z=[4930, 128],\n",
       "  y=8.69897,\n",
       "  reverse=[1],\n",
       "  group_id=0.0,\n",
       "  idx=119\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42e29782-ac6c-40c7-997b-b2be5beae970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  x=[1, 128],\n",
       "  z=[5075, 128],\n",
       "  y=8.69897,\n",
       "  reverse=[1],\n",
       "  group_id=0.0,\n",
       "  idx=120\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d8f57b-99fd-4cf1-bd0c-e768d6430389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  85.3664],\n",
       "        [-194.5437]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = dataset_train[0].x.to(device)\n",
    "x1 = dataset_train[1].x.to(device)\n",
    "x = torch.concat((x,x1))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82463cb0-8000-4954-a5cd-86878369517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/190 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroDataBatch(\n",
      "  x=[3, 128],\n",
      "  z=[14210, 128],\n",
      "  y=[3],\n",
      "  reverse=[3],\n",
      "  group_id=[3],\n",
      "  idx=[3]\n",
      ")\n",
      "torch.Size([3, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/190 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(data_loader_tr):\n",
    "    print(data)\n",
    "    y = data.y.to(device)\n",
    "    x = data.x.to(device)\n",
    "    data.group_id = data.group_id.to(device)\n",
    "    outputs = model(x)\n",
    "    print(outputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6829ada7-4442-4c15-8edc-d63519422704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:01<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:01<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:02<00:00,  4.46it/s]\n",
      " 44%|████▍     | 4/9 [00:01<00:01,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader_tr):\n\u001b[1;32m      3\u001b[0m         y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m         x \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1207\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1173\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1173\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1175\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/multiprocessing/queues.py:116\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/multiprocessing/reductions.py:90\u001b[0m, in \u001b[0;36mrebuild_tensor\u001b[0;34m(cls, storage, metadata)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrebuild_tensor\u001b[39m(\u001b[38;5;28mcls\u001b[39m, storage, metadata):\n\u001b[1;32m     89\u001b[0m     storage_offset, size, stride, requires_grad \u001b[38;5;241m=\u001b[39m metadata\n\u001b[0;32m---> 90\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rebuild_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;66;03m# we have to pass requires_grad into constructor, rather than set it as an\u001b[39;00m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;66;03m# attribute later, because it's an important check for Integer Tensors to\u001b[39;00m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# have requires_grad=False (or else they raise an error)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter(t, requires_grad\u001b[38;5;241m=\u001b[39mrequires_grad)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/_utils.py:134\u001b[0m, in \u001b[0;36m_rebuild_tensor\u001b[0;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_untyped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mset_(storage\u001b[38;5;241m.\u001b[39m_untyped(), storage_offset, size, stride)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for data in tqdm(data_loader_tr):\n",
    "        y = data.y.to(device)\n",
    "        x = data.x.to(device)\n",
    "        data.group_id = data.group_id.to(device)\n",
    "        outputs = model(x)\n",
    "        loss, ratio = model.my_loss(outputs, y, data.group_id)\n",
    "        print(loss)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6f3d36f7-280e-4d35-b911-787c069a422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 1, 3, 2, 1, 4, 3, 2, 1, 5, 4, 3, 2, 1, 6, 5, 4, 3, 2, 1, 7, 6, 5,\n",
      "        4, 3, 2, 1, 8, 7, 6, 5, 4, 3, 2, 1, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
      "       device='cuda:0')\n",
      "Total valid pairs: 45.000, reversed: 45.000, reverse ratio: 1.000\n"
     ]
    }
   ],
   "source": [
    "outputs = torch.arange(0,10).to(device)\n",
    "y = torch.arange(0,10).to(device)\n",
    "group_id = torch.ones(10).to(device)\n",
    "model = TBNet().to(device)\n",
    "loss = model.my_loss(outputs, y, group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7587896c-44da-49e3-8f41-81e81cbd588c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m(\u001b[38;5;241m500\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": [
    "exp(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17da4c6-9226-4d59-9c37-621b5e355f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tankbind_py38]",
   "language": "python",
   "name": "conda-env-tankbind_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
