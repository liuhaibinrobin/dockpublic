{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/main_tankbind/tankbind_prototype/repaire_dataset_prototype.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btankbind/home/jovyan/main_tankbind/tankbind_prototype/repaire_dataset_prototype.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btankbind/home/jovyan/main_tankbind/tankbind_prototype/repaire_dataset_prototype.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfeature_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m generate_sdf_from_smiles_using_rdkit\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btankbind/home/jovyan/main_tankbind/tankbind_prototype/repaire_dataset_prototype.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m kekule_smiles \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/home/jovyan/dataspace/Prototype/tables/info_core_pockets.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mkekule_smiles\u001b[39m.\u001b[39munique())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btankbind/home/jovyan/main_tankbind/tankbind_prototype/repaire_dataset_prototype.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m smiles_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m/home/jovyan/dataspace/Prototype/smiles_dict.pt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1147\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1429\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1425\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1426\u001b[0m     )\n\u001b[0;32m-> 1429\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   1430\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   1473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from feature_utils import generate_sdf_from_smiles_using_rdkit\n",
    "\n",
    "info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/info_core_pockets.csv\")\n",
    "kekule_smiles = list(info.kekule_smiles.unique())\n",
    "smiles_names = list(info.smiles_name.unique())\n",
    "smiles_dict = torch.load(\"/home/jovyan/dataspace/Prototype/smiles_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据 `kekule_smiles` 生成小分子文件。只需要执行一次。\n",
    "这里或许应该生成一份，shifted 的小分子文件！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    error_smiles = []\n",
    "    for i, smiles in tqdm(enumerate(kekule_smiles), total=len(kekule_smiles)):\n",
    "        try:\n",
    "            smiles_name = smiles_dict[smiles]\n",
    "            generate_sdf_from_smiles_using_rdkit(smiles=smiles, rdkitMolFile=f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs_shifted/{smiles_name}.sdf\", shift_dis=30)\n",
    "        except:\n",
    "            error_smiles.append((smiles, smiles_dict[smiles]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_utils import extract_torchdrug_feature_from_mol\n",
    "from feature_utils import read_mol\n",
    "\n",
    "compound_dict = {}\n",
    "skip_smiles_list = []\n",
    "for smiles_name in tqdm(smiles_names):\n",
    "    mol, _ = read_mol(f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs_shifted/{smiles_name}.sdf\", None)\n",
    "    # extract features from sdf.\n",
    "    try:\n",
    "        compound_dict[smiles_name] = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)  # self-dock set has_LAS_mask to true\n",
    "    except Exception as e:\n",
    "        print(smiles_name, e)\n",
    "        skip_smiles_list.append(smiles_name)\n",
    "\n",
    "skip_smiles_list = ['smiles_5544', 'smiles_39785', 'smiles_39786', 'smiles_39787', 'smiles_39788', 'smiles_40760', 'smiles_40762', 'smiles_40763', 'smiles_40764', 'smiles_40766', 'smiles_43789']\n",
    "tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "torch.save(compound_dict, f\"{tankbind_data_path}/compound_torchdrug_features_shifted.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
