{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1604e886",
   "metadata": {},
   "source": [
    "# `重要`\n",
    "在克隆本 git 项目后，如果未按照现有方式挂载 `dataspace` 数据卷，则需要按情况将每一个代码块的 `processed=True` 修改为 `processed=False`，然后运行，以将处理后的数据保存至某个文件夹（原为`dataspace/Prototype`），并在`tankbind_prototype/datasets` 下生成训练、测试用数据集。\n",
    "若成功挂载 `dataspace`，请跳到本脚本的 「<font color='gold'>「从这里开始」</font>数据集构建」，并以该处开始构建数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a72580",
   "metadata": {},
   "source": [
    "# overview\n",
    "\n",
    "### Preperation | 路径准备\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b0398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "pdbbind_path = \"/home/jovyan/dataspace/PDBbind2020/all_pdbbind\"\n",
    "proto_path = \"/home/jovyan/dataspace/Prototype\"\n",
    "p2rank = \"bash /home/jovyan/TankBind/p2rank_2.3/prank\"\n",
    "tankbind_src_folder_path = \"../tankbind_prototype/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85d36f5",
   "metadata": {},
   "source": [
    "## 数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb6cae",
   "metadata": {},
   "source": [
    "#### 读取表格和 `pdb` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366e1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    session_table = pd.read_csv(\"/home/jovyan/dataspace/Liyou/jingsen.csv\")\n",
    "\n",
    "    sample_id = list(range(len(session_table)))\n",
    "    sample_id = [\"ID_\"+str(_) for _ in sample_id]\n",
    "    session_table['sample_id'] = sample_id\n",
    "    \n",
    "    pdb_in_session = session_table.pdb_id.unique()\n",
    "    pdb_in_pdbbind = os.listdir(pdbbind_path)\n",
    "    for _ in tqdm(pdb_in_session):\n",
    "        if _.lower() not in pdb_in_pdbbind:\n",
    "            print(_, end=\" \")\n",
    "    # All PDBs in session table could be found in pdbbind2020\n",
    "    pdb_in_session = list(pdb_in_sessio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24195aa7",
   "metadata": {},
   "source": [
    "#### 遍历 PDBBind2020 数据库的 ligand 文件，为读取最佳口袋坐标做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd411510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    from feature_utils import read_mol\n",
    "    from rdkit import RDLogger\n",
    "    RDLogger.DisableLog('rdApp.*')\n",
    "    pdb_list = []\n",
    "    problem_list = []\n",
    "    for pdb in tqdm(pdb_in_session):\n",
    "        pdb = pdb.lower()\n",
    "        sdf_fileName = f\"{pdbbind_path}/{pdb}/{pdb}_ligand.sdf\"\n",
    "        mol2_fileName = f\"{pdbbind_path}/{pdb}/{pdb}_ligand.mol2\"\n",
    "        mol, problem = read_mol(sdf_fileName, mol2_fileName)\n",
    "        if problem:\n",
    "            problem_list.append(pdb)\n",
    "            continue\n",
    "        pdb_list.append(pdb)\n",
    "    print(problem_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821e320",
   "metadata": {},
   "source": [
    "`problem_list = ['2foy', '2fou', '2fov', '3zp9', '1h07', '3dwb', '1a7x', '1qpf', '4qxs', '2ovz', '1hv5', '1dmt', '3fuc', '4g8l', '1tlp', '4dt6', '3bwf', '3ntp', '2e94', '4lkm', '3mi2', '3gep', '3ggj', '1bzy', '4bxk', '2oc2', '3kck', '3djx', '2pll', '5aqk', '5ipc', '5kly', '5hlm', '4l4l', '4jbs', '5kyk', '3bbb', '4e67', '3fvh', '4lkl', '4r07', '4loi', '3hik', '4e9d', '4e9c', '5km1', '5kma', '4k10']`\n",
    "\n",
    "针对这些蛋白，将读取文件坐标找到最佳口袋。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa4901",
   "metadata": {},
   "source": [
    "#### 准备表格\n",
    "最终结果已导出为 `multiton_table.csv`，故前面的步骤都跳过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    session_table['session_au'] = session_table['assay_id'].astype(str) + \"_\" + session_table['uniprot_id']\n",
    "    session_count = session_table[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    session_count.reset_index(inplace=True)\n",
    "\n",
    "    singleton_session = list(session_count[session_count.kekule_smiles==1].session_au)\n",
    "    multiton_session = list(session_count[session_count.kekule_smiles!=1].session_au)\n",
    "\n",
    "    ms_dict ={_:\"singleton\" for _ in singleton_session}\n",
    "    ms_dict.update({_:\"multiton\" for _ in multiton_session})\n",
    "\n",
    "    session_table['session_au_usability'] = session_table.session_au.apply(lambda x: ms_dict[x])\n",
    "    \n",
    "    \n",
    "    from feature_utils import generate_sdf_from_smiles_using_rdkit\n",
    "    multiton_table = session_table[session_table.session_au_usability==\"multiton\"]\n",
    "    multiton_table\n",
    "\n",
    "    kekule_smiles = list(multiton_table.kekule_smiles.unique())\n",
    "    len(kekule_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16defc07",
   "metadata": {},
   "source": [
    "生成 `smiles_name` 词典，以免直接用 `kekule_smiles` 命名文件导致的问题。\n",
    "\n",
    "读取 `smiles_name` 词典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887cfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    import torch\n",
    "    smiles_dict = {}\n",
    "    for i, smiles in enumerate(kekule_smiles):\n",
    "        smiles_dict[smiles] = f\"smiles_{i}\"\n",
    "    import torch\n",
    "    torch.save(smiles_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_smiles_dict.pt\")\n",
    "else:\n",
    "    smiles_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_smiles_dict.pt\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b25cd",
   "metadata": {},
   "source": [
    "根据 `kekule_smiles` 生成小分子文件。只需要执行一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca91648",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    error_smiles = []\n",
    "    for i, smiles in tqdm(enumerate(kekule_smiles), total=len(kekule_smiles)):\n",
    "        try:\n",
    "            smiles_name = smiles_dict[smiles]\n",
    "            generate_sdf_from_smiles_using_rdkit(smiles=smiles, rdkitMolFile=f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs/{smiles_name}.sdf\", shift_dis=0)\n",
    "        except:\n",
    "            error_smiles.append((smiles, smiles_dict[smiles]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348a097",
   "metadata": {},
   "source": [
    "清理错误的样本，并保存最后的 `multiton_table`。过程只需要执行一次。\n",
    "```\n",
    "error_smiles = [\"smiles_12096\",  \"smiles_12097\", \"smiles_12098\", \"smiles_37527\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7b5803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89335/2615119571.py:42: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_with_smiles_name.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    smiles_files = os.listdir(\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs\")\n",
    "    smiles_files = [_.replace(\".sdf\", \"\") for _ in smiles_files]\n",
    "\n",
    "    error_smiles = []\n",
    "    for _ in tqdm(kekule_smiles):\n",
    "        if smiles_dict[_] not in smiles_files:\n",
    "            error_smiles.append((_, smiles_dict[_]))\n",
    "\n",
    "    real_error_smiles = []\n",
    "    print(\"LENGTH\", len(error_smiles))\n",
    "    a = 0\n",
    "    for i, error in tqdm(enumerate(error_smiles), total=len(error_smiles)):\n",
    "        smiles, smiles_name = error\n",
    "        try:\n",
    "            generate_sdf_from_smiles_using_rdkit(smiles=smiles, rdkitMolFile=f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs/{smiles_name}.sdf\", shift_dis=0)\n",
    "        except:\n",
    "            a += 1\n",
    "            print(smiles_name, end=\" \")\n",
    "            real_error_smiles.append((smiles, smiles_dict[smiles]))\n",
    "    print(\"\\nLENGTH\", a)\n",
    "\n",
    "\n",
    "    all_smiles_file = os.listdir(\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs\")\n",
    "    all_smiles_file = [_.replace(\".sdf\", \"\") for _ in all_smiles_file]\n",
    "\n",
    "\n",
    "    for _ in tqdm(kekule_smiles):\n",
    "        if smiles_dict[_] not in all_smiles_file:\n",
    "            print(smiles_dict[_])\n",
    "\n",
    "\n",
    "    multiton_table['kekule_smiles_name'] = multiton_table.kekule_smiles.apply(lambda x: smiles_dict[x])\n",
    "\n",
    "\n",
    "    error_smiles = [\"smiles_12096\",  \"smiles_12097\", \"smiles_12098\", \"smiles_37527\"]\n",
    "\n",
    "\n",
    "    multiton_table = multiton_table[~multiton_table.kekule_smiles_name.isin(error_smiles)]\n",
    "    multiton_table.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_with_smiles_name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cae85",
   "metadata": {},
   "source": [
    "#### 读取 `smiles_dict.pt`，读取 `multiton_table.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a64cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90545/2114790264.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_with_smiles_name.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    smiles_dict = torch.load(\"/home/jovyan/dataspace/Prototype/FULL_smiles_dict.pt\")\n",
    "    multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_with_smiles_name.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e3221",
   "metadata": {},
   "source": [
    "### 蛋白质：口袋切分与特征构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db0d33",
   "metadata": {},
   "source": [
    "#### 使用 `p2rank` 生成口袋「略」。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a68298",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if False:\n",
    "    p2rank_prediction_folder = \"/home/jovyan/dataspace/Prototype/p2rank_results\"\n",
    "    os.system(f\"mkdir -p {p2rank_prediction_folder}\")\n",
    "    ds = f\"{p2rank_prediction_folder}/protein_list.ds\"\n",
    "    with open(ds, \"w\") as out:\n",
    "        for pdb in ##TODO: protein_names\n",
    "            out.write(f\"../{TODO: foldernames}/{pdb}_protein.pdb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30455de8",
   "metadata": {},
   "source": [
    "#### 检查已有的 `p2rank` 结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47186cc8",
   "metadata": {},
   "source": [
    "根据 `multiton_table.csv` 得到当前的 `pdb_list`。\n",
    "\n",
    "检查是否所有的 `pdb` 口袋都能在 `p2rank` 输出文件夹中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516417a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/9092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2RANK YES.\n"
     ]
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    pdb_list = [_.lower() for _ in list(multiton_table.pdb_id.unique())]\n",
    "    p2rank_prediction_folder = \"/home/jovyan/dataspace/Prototype/p2rank_results\"\n",
    "\n",
    "    _ = os.listdir(p2rank_prediction_folder)\n",
    "    pdb_without_p2rank_result = []\n",
    "    for pdb in tqdm(pdb_list):\n",
    "        if f\"{pdb.lower()}_protein.pdb_predictions.csv\" in _:\n",
    "            continue\n",
    "        else:\n",
    "            pdb_without_p2rank_result.append(pdb)\n",
    "            print(pdb, end=\", \")\n",
    "    if pdb_without_p2rank_result == []:\n",
    "        print(\"P2RANK YES.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae61cb5",
   "metadata": {},
   "source": [
    "####  准备 `protein_features`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2509e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/9092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    os.system(f\"mkdir -p {tankbind_data_path}\")\n",
    "    pdb_list = [_.lower() for _ in list(multiton_table.pdb_id.unique())]\n",
    "    d_list = []\n",
    "\n",
    "    for name in tqdm(pdb_list):\n",
    "        p2rankFile = f\"{p2rank_prediction_folder}/{name}_protein.pdb_predictions.csv\"\n",
    "        d = pd.read_csv(p2rankFile)\n",
    "        d.columns = d.columns.str.strip()\n",
    "        d_list.append(d.assign(name=name))\n",
    "    d = pd.concat(d_list).reset_index(drop=True)\n",
    "    d.reset_index(drop=True).to_feather(f\"{tankbind_data_path}/p2rank_result.feather\")\n",
    "\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    d = pd.read_feather(f\"{tankbind_data_path}/p2rank_result.feather\")\n",
    "\n",
    "    pockets_dict = {}\n",
    "    for name in tqdm(pdb_list):\n",
    "        pockets_dict[name] = d[d.name == name].reset_index(drop=True)\n",
    "        \n",
    "    torch.save(pockets_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pockets_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "333018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    from feature_utils import get_protein_feature\n",
    "\n",
    "    input_ = []\n",
    "    protein_embedding_folder = f\"{tankbind_data_path}/gvp_protein_embedding\"\n",
    "    os.system(f\"mkdir -p {protein_embedding_folder}\")\n",
    "    for pdb in tqdm(pdb_list):\n",
    "        proteinFile = f\"{pdbbind_path}/{pdb}/{pdb}_protein.pdb\"\n",
    "        toFile = f\"{protein_embedding_folder}/{pdb}.pt\"\n",
    "        x = (pdb, proteinFile, toFile)\n",
    "        input_.append(x)\n",
    "        \n",
    "\n",
    "    from Bio.PDB import PDBParser\n",
    "    from feature_utils import get_clean_res_list\n",
    "    import torch\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    def batch_run(x):\n",
    "        protein_dict = {}\n",
    "        pdb, proteinFile, toFile = x\n",
    "        parser = PDBParser(QUIET=True)\n",
    "        s = parser.get_structure(pdb, proteinFile)\n",
    "        res_list = get_clean_res_list(s.get_residues(), verbose=False, ensure_ca_exist=True)\n",
    "        protein_dict[pdb] = get_protein_feature(res_list)\n",
    "        torch.save(protein_dict, toFile)\n",
    "        \n",
    "\n",
    "    import mlcrate as mlc\n",
    "    import os\n",
    "    pool = mlc.SuperPool(64)\n",
    "    pool.pool.restart()\n",
    "    _ = pool.map(batch_run,input_)\n",
    "    pool.exit()\n",
    "\n",
    "\n",
    "    import torch\n",
    "    protein_dict = {}\n",
    "    for pdb in tqdm(name_list):\n",
    "        protein_dict.update(torch.load(f\"{protein_embedding_folder}/{pdb}.pt\"))\n",
    "        \n",
    "        \n",
    "    torch.save(protein_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49af930",
   "metadata": {},
   "source": [
    "#### 「折叠」读取已保存的 `protein_dict` 和 `pockets_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b9191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    protein_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "    pockets_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_pockets_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82962a8",
   "metadata": {},
   "source": [
    "### 「折叠」小分子：特征构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b377bf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/113099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles_5544 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Ag`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `As`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Te`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles_39785 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39786 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39787 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39788 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40760 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40762 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40763 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40764 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40766 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_43789 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    from feature_utils import extract_torchdrug_feature_from_mol\n",
    "    from feature_utils import read_mol\n",
    "\n",
    "    compound_dict = {}\n",
    "    skip_smiles_list = []\n",
    "    for smiles_name in tqdm(multiton_table.kekule_smiles_name.unique()):\n",
    "        mol, _ = read_mol(f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs/{smiles_name}.sdf\", None)\n",
    "        # extract features from sdf.\n",
    "        try:\n",
    "            compound_dict[smiles_name] = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)  # self-dock set has_LAS_mask to true\n",
    "        except Exception as e:\n",
    "            print(smiles_name, e)\n",
    "            skip_smiles_list.append(smiles_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32029a29",
   "metadata": {},
   "source": [
    "```\n",
    "skip_smiles_list = ['smiles_5544', 'smiles_39785', 'smiles_39786', 'smiles_39787', 'smiles_39788', 'smiles_40760', 'smiles_40762', 'smiles_40763', 'smiles_40764', 'smiles_40766', 'smiles_43789']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "518346e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    torch.save(compound_dict, f\"/home/jovyan/dataspace/Prototype/dicts/FULL_compound_torchdrug_features.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6cabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    multiton_table = multiton_table[~multiton_table.kekule_smiles_name.isin(skip_smiles_list)]\n",
    "    multiton_table.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d59278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90545/3151936896.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_v2.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_v2.csv\", index_col=0)\n",
    "    multiton_table['session_aus'] = multiton_table['session_au'] + \"_\" + multiton_table['kekule_smiles']\n",
    "    data = multiton_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a55b64",
   "metadata": {},
   "source": [
    "### 表格处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a29b2",
   "metadata": {},
   "source": [
    "#### 导入分组文件以进行 `train-ood-iid-val` 分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b763d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    drugood_split = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/non_drugood_split2.csv\")\n",
    "    drugood_split=drugood_split.fillna(\"-\")\n",
    "    drugood_split.split_tag = drugood_split.split_tag.apply(lambda x: \"train\" if x==\"-\" else x)\n",
    "    drugood_split[\"session_aus\"] = drugood_split['assay_id'].astype(str) + \"_\" + drugood_split['uniprot_id'] + \"_\" + drugood_split['kekule_smiles']\n",
    "    drugood_split=drugood_split[['session_aus', 'split_tag']]\n",
    "    \n",
    "    data = pd.merge(left=multiton_table, right=drugood_split, how=\"left\", on=\"session_aus\")\n",
    "    data.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb3709",
   "metadata": {},
   "source": [
    "#### 读取 `raw_info.csv` 为 `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8cc6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    data = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f45c98",
   "metadata": {},
   "source": [
    "#### 处理`data`生成 `info` 并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c1f9eaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/695316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886176\n"
     ]
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    info = []\n",
    "    err_pdb_list=[]\n",
    "    for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        \n",
    "        sample_id = line['sample_id']\n",
    "        pdb_id = line['pdb_id']\n",
    "        uniprot_id = line['uniprot_id']\n",
    "        assay_id = line['assay_id']\n",
    "        smiles_name = line['kekule_smiles_name']\n",
    "        smiles = line['kekule_smiles']\n",
    "        session_au = line['session_au']\n",
    "        session_aus = line['session_aus']\n",
    "        \n",
    "        value = line['value']\n",
    "        docking_score = line['docking_score']\n",
    "        mmgbsa_binding_energy = line['mmgbsa_binding_energy']\n",
    "        qed = line[\"qed\"]\n",
    "        \n",
    "        split_tag = line['split_tag']\n",
    "        \n",
    "        protein_name = pdb_id.lower()\n",
    "        try:\n",
    "            pocket = pockets_dict[protein_name].head(20)\n",
    "        except:\n",
    "            err_pdb_list.append(pdb)\n",
    "            continue\n",
    "        pocket.columns = pocket.columns.str.strip()\n",
    "        pocket_coms = pocket[['center_x', 'center_y', 'center_z']].values\n",
    "\n",
    "        # protein center as a block.\n",
    "        protein_com = protein_dict[protein_name][0].numpy().mean(axis=0).astype(float).reshape(1, 3)\n",
    "        info.append([sample_id, pdb_id, uniprot_id, assay_id, smiles_name, smiles, session_au, session_aus, protein_com, protein_name+\"_c\", \n",
    "                     value, docking_score, mmgbsa_binding_energy, qed, split_tag])\n",
    "        \n",
    "        for idx, pocket_line in pocket.iterrows():\n",
    "            pdb_idx = f\"{protein_name}_{idx}\"\n",
    "            info.append([sample_id, pdb_id, uniprot_id, assay_id, smiles_name, smiles, session_au, session_aus, pocket_coms[idx].reshape(1, 3), pdb_idx, \n",
    "                         value, docking_score, mmgbsa_binding_energy, qed, split_tag])\n",
    "            \n",
    "    info = pd.DataFrame(\n",
    "        info, \n",
    "        columns=['sample_id', 'pdb_id', 'uniprot_id', 'assay_id', 'smiles_name', 'kekule_smiles', 'session_au', 'session_aus', 'pocket_com', 'pocket_name', \n",
    "                 'value', 'docking_score','mmgbsa_binding_energy', 'qed', 'split_tag'])\n",
    "    print(len(info))\n",
    "\n",
    "\n",
    "    len(err_pdb_list)\n",
    "    # 0\n",
    "\n",
    "\n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23c053",
   "metadata": {},
   "source": [
    "#### 读取 `info_all_pockets` 为 `info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "266b6295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa161c5a",
   "metadata": {},
   "source": [
    "#### 使用此前生成的 `ligand_coor_dict` 来指定口袋，生成 `pdb_id_to_pocket_name_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9dc100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    ligand_coor_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/ARC_ligand_coor_dict.pt\")\n",
    "    \n",
    "    \n",
    "    pdb_id_to_pocket_name_dict ={}\n",
    "    error_pdb_id_list = []\n",
    "    for PDB_id in tqdm(ligand_coor_dict, total=len(ligand_coor_dict)):\n",
    "        try:\n",
    "            pdb_id = PDB_id.lower()\n",
    "            ligand_center = ligand_coor_dict[PDB_id][0]\n",
    "            p2rankFile = f\"/home/jovyan/dataspace/Prototype/p2rank_results/{pdb_id}_protein.pdb_predictions.csv\"\n",
    "            pocket = pd.read_csv(p2rankFile)\n",
    "            pocket.columns = pocket.columns.str.strip()\n",
    "            pocket_coms = pocket[['center_x', 'center_y', 'center_z']].values\n",
    "            pocket_coms_with_center = np.concatenate([pocket_coms.mean(axis=0).reshape(1,3), pocket_coms])\n",
    "            pocket_names = [pdb_id + \"_c\"] + [pdb_id+\"_\"+str(i) for i in range(len(pocket_coms))]\n",
    "            right_ith = ((pocket_coms_with_center-ligand_center)**2).sum(axis=1).argmin()\n",
    "            right_name = pocket_names[right_ith]\n",
    "            pdb_id_to_pocket_name_dict[PDB_id] = right_name\n",
    "        except:\n",
    "            print(PDB_id, end = \" \")\n",
    "            error_pdb_id_list.append(PDB_id)\n",
    "            pdb_id_to_pocket_name_dict[PDB_id] = \"ERROR\"\n",
    "            \n",
    "    torch.save(pdb_id_to_pocket_name_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pdb_id_to_pocket_name_dict.pt\")\n",
    "    torch.save(error_pdb_id_list, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pdb_id_to_pocket_name_error_list.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cc476",
   "metadata": {},
   "source": [
    "#### 读取`pdb_id_to_pocket_name_dict`，并结合 `info_all_pockets` 构造出仅保留单个 `pocket` 的 `info_core_pocket`。\n",
    "错误的蛋白因为已标注为 `ERROR`，会因为没有名为 `ERROR` 的口袋而被略去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d6899a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    pdb_id_to_pocket_name_dict = torch.load(\"/home/jovyan/dataspace/Prototype/pdb_id_to_pocket_name_dict.pt\")\n",
    "    info['p2rank_core_pocket'] = info.apply(lambda x: pdb_id_to_pocket_name_dict[x.pdb_id] == x.pocket_name, axis=1)\n",
    "    \n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets_noted.csv\")\n",
    "    \n",
    "    info = info[info.p2rank_core_pocket==True] \n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_core_pocket.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d5f5e",
   "metadata": {},
   "source": [
    "#### 读取 `info_core_pocket`，该表格被用于构建最终数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/info_core_pocket.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1718f",
   "metadata": {},
   "source": [
    "针对 `val / test` 组的数据，额外提供一个根据 docking_score 预先指定口袋的 info_val_test_best_docking_score\n",
    "\n",
    "这一步在后续构建两个数据集时也进行了，所以可以不管这一格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "17adb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    from pandas import DataFrame\n",
    "    info_val_test = info[info.split_tag!=\"train\"]\n",
    "    info_val_test = info_val_test.sort_values('docking_score').groupby('session_aus').apply(DataFrame.head, n=1).reset_index(drop=True)\n",
    "    info_val_test.to_csv(\"/home/jovyan/dataspace/Prototype/tables/info_extra_for_val_and_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41c212",
   "metadata": {},
   "source": [
    "针对 info 和 info_val_test 进行额外的 session_au_usability_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "73b22a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    info_count = info[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    info_count.reset_index(inplace=True)\n",
    "    info_singleton = list(info_count[info_count.kekule_smiles==1].session_au)\n",
    "    info_multiton = list(info_count[info_count.kekule_smiles!=1].session_au)\n",
    "    ms_dict ={_:\"singleton\" for _ in info_singleton}\n",
    "    ms_dict.update({_:\"multiton\" for _ in info_multiton})\n",
    "    info['session_au_usability'] = info.session_au.apply(lambda x: ms_dict[x])\n",
    "    info = info[info.session_au_usability==\"multiton\"]\n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.csv\")\n",
    "    info.to_pickle(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a4d9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = True\n",
    "if not processed:\n",
    "    info_count = info_val_test[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    info_count.reset_index(inplace=True)\n",
    "    info_singleton = list(info_count[info_count.kekule_smiles==1].session_au)\n",
    "    info_multiton = list(info_count[info_count.kekule_smiles!=1].session_au)\n",
    "    ms_dict ={_:\"singleton\" for _ in info_singleton}\n",
    "    ms_dict.update({_:\"multiton\" for _ in info_multiton})\n",
    "    info_val_test['session_au_usability'] = info_val_test.session_au.apply(lambda x: ms_dict[x])\n",
    "    info_val_test = info_val_test[info_val_test.session_au_usability==\"multiton\"]\n",
    "    info_val_test.to_csv(\"/home/jovyan/dataspace/Prototype/tables/info_extra_for_val_and_test_multiton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461c996",
   "metadata": {},
   "source": [
    "# <font color='gold'>「从这里开始」</font>数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4afeb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "pdbbind_path = \"/home/jovyan/dataspace/PDBbind2020/all_pdbbind\"\n",
    "proto_path = \"/home/jovyan/dataspace/Prototype\"\n",
    "p2rank = \"bash /home/jovyan/TankBind/p2rank_2.3/prank\"\n",
    "tankbind_src_folder_path = \"../tankbind_prototype/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bd5bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "protein_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "compound_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_compound_torchdrug_features.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28571a7",
   "metadata": {},
   "source": [
    "读取 `info` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fb2a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_pickle(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.pkl\")\n",
    "#session type 使用 同assay同pdbid 或者  同assay同uniprot\n",
    "info[\"session_ap\"] = info['assay_id'].astype(str) + \"_\" + info['pdb_id']\n",
    "info[\"session_aps\"]=info[\"session_ap\"]+\"_\"+info[\"kekule_smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ae431ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/data.pt', '/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/protein.pt', '/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/compound.pt']\n"
     ]
    }
   ],
   "source": [
    "from data_prototype import TankBindDataSet_prototype\n",
    "\n",
    "toFileFull = f\"/home/jovyan/main_tankbind/dataset_prototype/full/dataset\"\n",
    "os.system(f\"rm -rf {toFileFull}\")\n",
    "os.system(f\"mkdir -p {toFileFull}\")\n",
    "dataset = TankBindDataSet_prototype(toFileFull, data=info, protein_dict=protein_dict, compound_dict=compound_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae5ea885",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "t_dict = {}\n",
    "data = dataset.data\n",
    "\n",
    "# for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "#     d = dataset[i]\n",
    "#     sample_id = line['sample_id']\n",
    "#     p_length = d['node_xyz'].shape[0]\n",
    "#     c_length = d['coords'].shape[0]\n",
    "#     y_length = d['y'].shape[0]\n",
    "#     t.append([i, sample_id, p_length, c_length, y_length])\n",
    "#     t_dict[sample_id] = [i, sample_id, p_length, c_length, y_length]\n",
    "    \n",
    "# torch.save(t, \"/home/jovyan/dataspace/Prototype/tables/FULL_supplementary.pt\")\n",
    "# torch.save(t_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_supplementary_dict.pt\")\n",
    "t=torch.load( \"/home/jovyan/dataspace/Prototype/tables/FULL_supplementary.pt\")\n",
    "t_dict=torch.load( \"/home/jovyan/dataspace/Prototype/dicts/FULL_supplementary_dict.pt\")\n",
    "\n",
    "t = pd.DataFrame(t, columns=['index', 'sample_id', 'p_length', 'c_length', 'y_length'])\n",
    "t.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_supplementary.csv\")\n",
    "\n",
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee0ec6bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/dataspace/Prototype/tables/FULL_t.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m----> 2\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/jovyan/dataspace/Prototype/tables/FULL_t.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([data, t[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_length\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_length\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(data, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoFileFull\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/processed/data.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/betabind_py38/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/dataspace/Prototype/tables/FULL_t.csv'"
     ]
    }
   ],
   "source": [
    "# data = dataset.data\n",
    "# t = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_t.csv\", index_col=0)\n",
    "# data =pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "# torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fb600",
   "metadata": {},
   "source": [
    "### 验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0e59e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.csv\", index_col=0)\n",
    "#session type 使用 同assay同pdbid 或者  同assay同uniprot\n",
    "info[\"session_ap\"] = info['assay_id'].astype(str) + \"_\" + info['pdb_id']\n",
    "info[\"session_aps\"]=info[\"session_ap\"]+\"_\"+info[\"kekule_smiles\"]\n",
    "info.reset_index(inplace=True, drop=True)\n",
    "info.pocket_com = info.pocket_com.apply(lambda x: np.array([float(_) for _ in x.replace(\"[[\", \"\").replace(\"]]\", \"\").split()]))\n",
    "info2 = info[info.split_tag.isin([\"test\", 'iid_val', 'ood_val'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e40b33",
   "metadata": {},
   "source": [
    "同 `aus` 样本，不同 `pdb` 中抽取 `docking_score` 最低的一条。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25168f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info3 = info2.sort_values(by='docking_score', ascending=True).groupby('session_aus', as_index=False).first()\n",
    "info3.head(5)\n",
    "info3.to_pickle(\"/home/jovyan/dataspace/Prototype/tables/EXTRA_info_sole_pdb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcb88276",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pdbs = [_.lower() for _ in info2.pdb_id.unique()]\n",
    "small_smiles = list(info2.smiles_name.unique())\n",
    "\n",
    "protein_dict2 = {_:protein_dict[_] for _ in small_pdbs}\n",
    "compound_dict2 = {_:compound_dict[_] for _ in small_smiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "764c572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/data.pt', '/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/protein.pt', '/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/compound.pt']\n"
     ]
    }
   ],
   "source": [
    "toFileExtra = f\"/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130\"\n",
    "os.system(f\"rm -rf {toFileExtra}\")\n",
    "os.system(f\"mkdir -p {toFileExtra}\")\n",
    "\n",
    "from data_prototype import TankBindDataSet_prototype\n",
    "dataset = TankBindDataSet_prototype(toFileExtra, data=info3, protein_dict=protein_dict2, compound_dict=compound_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50c78f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "t_dict = {}\n",
    "data = dataset.data\n",
    "\n",
    "# for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "#     d = dataset[i]\n",
    "#     sample_id = line['sample_id']\n",
    "#     p_length = d['node_xyz'].shape[0]\n",
    "#     c_length = d['coords'].shape[0]\n",
    "#     y_length = d['y'].shape[0]\n",
    "#     t.append([i, sample_id, p_length, c_length, y_length])\n",
    "#     t_dict[sample_id] = [i, sample_id, p_length, c_length, y_length]\n",
    "    \n",
    "# torch.save(t, \"/home/jovyan/dataspace/Prototype/tables/EXTRA_supplementary.pt\")\n",
    "# torch.save(t_dict, \"/home/jovyan/dataspace/Prototype/dicts/EXTRA_supplementary_dict.pt\")\n",
    "t=torch.load( \"/home/jovyan/dataspace/Prototype/tables/EXTRA_supplementary.pt\")\n",
    "t_dict=torch.load(\"/home/jovyan/dataspace/Prototype/dicts/EXTRA_supplementary_dict.pt\")\n",
    "\n",
    "t = pd.DataFrame(t, columns=['index', 'sample_id', 'p_length', 'c_length', 'y_length'])\n",
    "t.to_csv(\"/home/jovyan/dataspace/Prototype/tables/EXTRA_supplementary.csv\")\n",
    "\n",
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileExtra}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af902b98-185f-4b96-8691-e37a6e044e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
  },
  "kernelspec": {
   "display_name": "Python [conda env:betabind_py38]",
   "language": "python",
   "name": "conda-env-betabind_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
