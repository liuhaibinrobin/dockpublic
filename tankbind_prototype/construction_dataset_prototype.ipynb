{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a10f3d",
   "metadata": {},
   "source": [
    "# overview\n",
    "\n",
    "### Preperation | 路径准备\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a4988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "pdbbind_path = \"/home/jovyan/dataspace/PDBbind2020/all_pdbbind\"\n",
    "proto_path = \"/home/jovyan/dataspace/Prototype\"\n",
    "p2rank = \"bash /home/jovyan/TankBind/p2rank_2.3/prank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4d9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbind_src_folder_path = \"../tankbind_prototype/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f55e78",
   "metadata": {},
   "source": [
    "## 数据整理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20386343",
   "metadata": {},
   "source": [
    "#### 「折叠」读取表格和 `pdb` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd991a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    session_table = pd.read_csv(\"/home/jovyan/dataspace/Liyou/jingsen.csv\")\n",
    "\n",
    "    sample_id = list(range(len(session_table)))\n",
    "    sample_id = [\"ID_\"+str(_) for _ in sample_id]\n",
    "    session_table['sample_id'] = sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb4d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pdb_in_session = session_table.pdb_id.unique()\n",
    "    pdb_in_pdbbind = os.listdir(pdbbind_path)\n",
    "    for _ in tqdm(pdb_in_session):\n",
    "        if _.lower() not in pdb_in_pdbbind:\n",
    "            print(_, end=\" \")\n",
    "    # All PDBs in session table could be found in pdbbind2020\n",
    "    pdb_in_session = list(pdb_in_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e382698b",
   "metadata": {},
   "source": [
    "#### 「折叠」遍历 PDBBind2020 数据库的 ligand 文件，为读取最佳口袋坐标做准备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b011b9a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from feature_utils import read_mol\n",
    "    from rdkit import RDLogger\n",
    "    RDLogger.DisableLog('rdApp.*')\n",
    "    pdb_list = []\n",
    "    problem_list = []\n",
    "    for pdb in tqdm(pdb_in_session):\n",
    "        pdb = pdb.lower()\n",
    "        sdf_fileName = f\"{pdbbind_path}/{pdb}/{pdb}_ligand.sdf\"\n",
    "        mol2_fileName = f\"{pdbbind_path}/{pdb}/{pdb}_ligand.mol2\"\n",
    "        mol, problem = read_mol(sdf_fileName, mol2_fileName)\n",
    "        if problem:\n",
    "            problem_list.append(pdb)\n",
    "            continue\n",
    "        pdb_list.append(pdb)\n",
    "    print(problem_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75278490",
   "metadata": {},
   "source": [
    "`problem_list = ['2foy', '2fou', '2fov', '3zp9', '1h07', '3dwb', '1a7x', '1qpf', '4qxs', '2ovz', '1hv5', '1dmt', '3fuc', '4g8l', '1tlp', '4dt6', '3bwf', '3ntp', '2e94', '4lkm', '3mi2', '3gep', '3ggj', '1bzy', '4bxk', '2oc2', '3kck', '3djx', '2pll', '5aqk', '5ipc', '5kly', '5hlm', '4l4l', '4jbs', '5kyk', '3bbb', '4e67', '3fvh', '4lkl', '4r07', '4loi', '3hik', '4e9d', '4e9c', '5km1', '5kma', '4k10']`\n",
    "\n",
    "针对这些蛋白，将读取文件坐标找到最佳口袋。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdcef08",
   "metadata": {},
   "source": [
    "#### 「折叠」准备表格\n",
    "最终结果已导出为 `multiton_table.csv`，故前面的步骤都跳过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52613d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    session_table['session_au'] = session_table['assay_id'].astype(str) + \"_\" + session_table['uniprot_id']\n",
    "    session_count = session_table[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    session_count.reset_index(inplace=True)\n",
    "\n",
    "    singleton_session = list(session_count[session_count.kekule_smiles==1].session_au)\n",
    "    multiton_session = list(session_count[session_count.kekule_smiles!=1].session_au)\n",
    "\n",
    "    ms_dict ={_:\"singleton\" for _ in singleton_session}\n",
    "    ms_dict.update({_:\"multiton\" for _ in multiton_session})\n",
    "\n",
    "    session_table['session_au_usability'] = session_table.session_au.apply(lambda x: ms_dict[x])\n",
    "    \n",
    "    \n",
    "    from feature_utils import generate_sdf_from_smiles_using_rdkit\n",
    "    multiton_table = session_table[session_table.session_au_usability==\"multiton\"]\n",
    "    multiton_table\n",
    "\n",
    "    kekule_smiles = list(multiton_table.kekule_smiles.unique())\n",
    "    len(kekule_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8f28c",
   "metadata": {},
   "source": [
    "生成 `smiles_name` 词典，以免直接用 `kekule_smiles` 命名文件导致的问题。\n",
    "\n",
    "读取 `smiles_name` 词典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83646bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import torch\n",
    "    for i, smiles in enumerate(kekule_smiles):\n",
    "        smiles_dict[smiles] = f\"smiles_{i}\"\n",
    "    import torch\n",
    "    torch.save(smiles_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_smiles_dict.pt\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42748cb1",
   "metadata": {},
   "source": [
    "根据 `kekule_smiles` 生成小分子文件。只需要执行一次。\n",
    "这里或许应该生成一份，shifted 的小分子文件！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9183c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    error_smiles = []\n",
    "    for i, smiles in tqdm(enumerate(kekule_smiles), total=len(kekule_smiles)):\n",
    "        try:\n",
    "            smiles_name = smiles_dict[smiles]\n",
    "            generate_sdf_from_smiles_using_rdkit(smiles=smiles, rdkitMolFile=f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs_shifted/{smiles_name}.sdf\", shift_dis=0)\n",
    "        except:\n",
    "            error_smiles.append((smiles, smiles_dict[smiles]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cac8d7",
   "metadata": {},
   "source": [
    "清理错误的样本，并保存最后的 `multiton_table`。过程只需要执行一次。\n",
    "```\n",
    "error_smiles = [\"smiles_12096\",  \"smiles_12097\", \"smiles_12098\", \"smiles_37527\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36516c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89335/2615119571.py:42: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_with_smiles_name.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    smiles_files = os.listdir(\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs\")\n",
    "    smiles_files = [_.replace(\".sdf\", \"\") for _ in smiles_files]\n",
    "\n",
    "    error_smiles = []\n",
    "    for _ in tqdm(kekule_smiles):\n",
    "        if smiles_dict[_] not in smiles_files:\n",
    "            error_smiles.append((_, smiles_dict[_]))\n",
    "\n",
    "    real_error_smiles = []\n",
    "    print(\"LENGTH\", len(error_smiles))\n",
    "    a = 0\n",
    "    for i, error in tqdm(enumerate(error_smiles), total=len(error_smiles)):\n",
    "        smiles, smiles_name = error\n",
    "        try:\n",
    "            generate_sdf_from_smiles_using_rdkit(smiles=smiles, rdkitMolFile=f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs/{smiles_name}.sdf\", shift_dis=0)\n",
    "        except:\n",
    "            a += 1\n",
    "            print(smiles_name, end=\" \")\n",
    "            real_error_smiles.append((smiles, smiles_dict[smiles]))\n",
    "    print(\"\\nLENGTH\", a)\n",
    "\n",
    "\n",
    "    all_smiles_file = os.listdir(\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs\")\n",
    "    all_smiles_file = [_.replace(\".sdf\", \"\") for _ in all_smiles_file]\n",
    "\n",
    "\n",
    "    for _ in tqdm(kekule_smiles):\n",
    "        if smiles_dict[_] not in all_smiles_file:\n",
    "            print(smiles_dict[_])\n",
    "\n",
    "\n",
    "    multiton_table['kekule_smiles_name'] = multiton_table.kekule_smiles.apply(lambda x: smiles_dict[x])\n",
    "\n",
    "\n",
    "    error_smiles = [\"smiles_12096\",  \"smiles_12097\", \"smiles_12098\", \"smiles_37527\"]\n",
    "\n",
    "\n",
    "    multiton_table = multiton_table[~multiton_table.kekule_smiles_name.isin(error_smiles)]\n",
    "    multiton_table.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_with_smiles_name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da362351",
   "metadata": {},
   "source": [
    "#### 「折叠」读取 `smiles_dict.pt`，读取 `multiton_table.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c38013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90545/2114790264.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_with_smiles_name.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    smiles_dict = torch.load(\"/home/jovyan/dataspace/Prototype/smiles_dict.pt\")\n",
    "    multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_with_smiles_name.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d90661",
   "metadata": {},
   "source": [
    "### 「折叠」<font color='red'>OUT OF DATE</font>  为 `RMSD Loss` 重写小分子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8246945",
   "metadata": {},
   "source": [
    "for ease of RMSD evaluation later, we renumber the atom index to be consistent with the smiles\n",
    "因为没有 RMSD loss， 可能不需要这一项，暂时跳过"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89cd6c",
   "metadata": {},
   "source": [
    "```\n",
    "from feature_utils import write_renumbered_sdf\n",
    "import os\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5969c38d",
   "metadata": {},
   "source": [
    "```\n",
    "toFolder = f\"{pre}/renumber_atom_index_same_as_smiles\"\n",
    "os.system(f\"mkdir -p {toFolder}\")\n",
    "for pdb in tqdm(pdb_list):\n",
    "    sdf_fileName = f\"{pre}/{pdb}/{pdb}_ligand.sdf\"\n",
    "    mol2_fileName = f\"{pre}/{pdb}/{pdb}_ligand.mol2\"\n",
    "    toFile = f\"{toFolder}/{pdb}.sdf\"\n",
    "    write_renumbered_sdf(toFile, sdf_fileName, mol2_fileName)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c89b1",
   "metadata": {},
   "source": [
    "### 「折叠」<font color='red'>OUT OF DATE</font> `P2RANK` 的 `pdb` 预处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597877f1",
   "metadata": {},
   "source": [
    "process PDBbind proteins, removing extra chains, cutoff 10A\n",
    "这些步骤被跳过，我们会直接使用 pdb 文件切出的口袋。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e1b28",
   "metadata": {},
   "source": [
    "```\n",
    "toFolder = f\"{pre}/protein_remove_extra_chains_10A/\"\n",
    "os.system(f\"mkdir -p {toFolder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43b677",
   "metadata": {},
   "source": [
    "```\n",
    "input_ = []\n",
    "cutoff = 10\n",
    "for pdb in data.pdb.values:\n",
    "    pdbFile = f\"{pre}/{pdb}/{pdb}_protein.pdb\"\n",
    "    ligandFile = f\"{pre}/renumber_atom_index_same_as_smiles/{pdb}.sdf\"\n",
    "    toFile = f\"{toFolder}/{pdb}_protein.pdb\"\n",
    "    x = (pdbFile, ligandFile, cutoff, toFile)\n",
    "    input_.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2301fa",
   "metadata": {},
   "source": [
    "```\n",
    "from feature_utils import select_chain_within_cutoff_to_ligand_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e471f9c",
   "metadata": {},
   "source": [
    "```\n",
    "import mlcrate as mlc\n",
    "import os\n",
    "pool = mlc.SuperPool(64)\n",
    "pool.pool.restart()\n",
    "_ = pool.map(select_chain_within_cutoff_to_ligand_v2,input_)\n",
    "pool.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f7ba1",
   "metadata": {},
   "source": [
    "\n",
    "##### previously, I found that 2r1w has no chain near the ligand.\n",
    "```\n",
    "data = data.query(\"pdb != '2r1w'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8db079a",
   "metadata": {},
   "source": [
    "### 「折叠」蛋白质：口袋切分与特征构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b53cd9",
   "metadata": {},
   "source": [
    "#### 「折叠」使用 `p2rank` 生成口袋。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3aed14",
   "metadata": {},
   "source": [
    "```\n",
    "p2rank_prediction_folder = f\"{pre}/p2rank_protein_remove_extra_chains_10A\"\n",
    "os.system(f\"mkdir -p {p2rank_prediction_folder}\")\n",
    "ds = f\"{p2rank_prediction_folder}/protein_list.ds\"\n",
    "with open(ds, \"w\") as out:\n",
    "    for pdb in data.pdb.values:\n",
    "        out.write(f\"../protein_remove_extra_chains_10A/{pdb}_protein.pdb\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cba4a4",
   "metadata": {},
   "source": [
    "#### 「折叠」检查已有的 `p2rank` 结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c84a61d",
   "metadata": {},
   "source": [
    "根据 `multiton_table.csv` 得到当前的 `pdb_list`。\n",
    "\n",
    "检查是否所有的 `pdb` 口袋都能在 `p2rank` 输出文件夹中找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d470af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e073a8747649aaa822ce8e69beab86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P2RANK YES.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    pdb_list = [_.lower() for _ in list(multiton_table.pdb_id.unique())]\n",
    "    p2rank_prediction_folder = \"/home/jovyan/dataspace/Prototype/p2rank_results\"\n",
    "\n",
    "\n",
    "    _ = os.listdir(p2rank_prediction_folder)\n",
    "    pdb_without_p2rank_result = []\n",
    "    for pdb in tqdm(pdb_list):\n",
    "        if f\"{pdb.lower()}_protein.pdb_predictions.csv\" in _:\n",
    "            continue\n",
    "        else:\n",
    "            pdb_without_p2rank_result.append(pdb)\n",
    "            print(pdb, end=\", \")\n",
    "    if pdb_without_p2rank_result == []:\n",
    "        print(\"P2RANK YES.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86fc493",
   "metadata": {},
   "source": [
    "#### 「折叠」准备 `protein_features`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0500a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91149a5bfad2498d961371219080363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9092 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if False:\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    os.system(f\"mkdir -p {tankbind_data_path}\")\n",
    "    pdb_list = [_.lower() for _ in list(multiton_table.pdb_id.unique())]\n",
    "    d_list = []\n",
    "\n",
    "    for name in tqdm(pdb_list):\n",
    "        p2rankFile = f\"{p2rank_prediction_folder}/{name}_protein.pdb_predictions.csv\"\n",
    "        d = pd.read_csv(p2rankFile)\n",
    "        d.columns = d.columns.str.strip()\n",
    "        d_list.append(d.assign(name=name))\n",
    "    d = pd.concat(d_list).reset_index(drop=True)\n",
    "    d.reset_index(drop=True).to_feather(f\"{tankbind_data_path}/p2rank_result.feather\")\n",
    "\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    d = pd.read_feather(f\"{tankbind_data_path}/p2rank_result.feather\")\n",
    "\n",
    "    pockets_dict = {}\n",
    "    for name in tqdm(pdb_list):\n",
    "        pockets_dict[name] = d[d.name == name].reset_index(drop=True)\n",
    "        \n",
    "    torch.save(pockets_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pockets_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43dbc747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9aeee5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    from feature_utils import get_protein_feature\n",
    "\n",
    "    input_ = []\n",
    "    protein_embedding_folder = f\"{tankbind_data_path}/gvp_protein_embedding\"\n",
    "    os.system(f\"mkdir -p {protein_embedding_folder}\")\n",
    "    for pdb in name_list:\n",
    "        proteinFile = f\"{pdbbind_path}/{pdb}/{pdb}_protein.pdb\"\n",
    "        toFile = f\"{protein_embedding_folder}/{pdb}.pt\"\n",
    "        x = (pdb, proteinFile, toFile)\n",
    "        input_.append(x)\n",
    "        \n",
    "\n",
    "    from Bio.PDB import PDBParser\n",
    "    from feature_utils import get_clean_res_list\n",
    "    import torch\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    def batch_run(x):\n",
    "        protein_dict = {}\n",
    "        pdb, proteinFile, toFile = x\n",
    "        parser = PDBParser(QUIET=True)\n",
    "        s = parser.get_structure(pdb, proteinFile)\n",
    "        res_list = get_clean_res_list(s.get_residues(), verbose=False, ensure_ca_exist=True)\n",
    "        protein_dict[pdb] = get_protein_feature(res_list)\n",
    "        torch.save(protein_dict, toFile)\n",
    "        \n",
    "\n",
    "    import mlcrate as mlc\n",
    "    import os\n",
    "    pool = mlc.SuperPool(64)\n",
    "    pool.pool.restart()\n",
    "    _ = pool.map(batch_run,input_)\n",
    "    pool.exit()\n",
    "\n",
    "\n",
    "    import torch\n",
    "    protein_dict = {}\n",
    "    for pdb in tqdm(name_list):\n",
    "        protein_dict.update(torch.load(f\"{protein_embedding_folder}/{pdb}.pt\"))\n",
    "        \n",
    "        \n",
    "    torch.save(protein_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80144be9",
   "metadata": {},
   "source": [
    "#### 「折叠」读取已保存的 `protein_dict` 和 `pockets_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37cfd4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "    protein_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "    pockets_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_pockets_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c9a46",
   "metadata": {},
   "source": [
    "### 「折叠」小分子：特征构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67188992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0716a98ab2b94a039718a4d5cd2fe5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/113099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles_5544 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `K`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Ag`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `As`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torchdrug/data/feature.py:37: UserWarning: Unknown value `Te`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles_39785 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39786 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39787 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_39788 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40760 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40762 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40763 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40764 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_40766 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n",
      "smiles_43789 max(): Expected reduction dim to be specified for input.numel() == 0. Specify the reduction dim with the 'dim' argument.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from feature_utils import extract_torchdrug_feature_from_mol\n",
    "    from feature_utils import read_mol\n",
    "\n",
    "    compound_dict = {}\n",
    "    skip_smiles_list = []\n",
    "    for smiles_name in tqdm(multiton_table.kekule_smiles_name.unique()):\n",
    "        mol, _ = read_mol(f\"/home/jovyan/dataspace/Prototype/rdkit_generated_sdfs/{smiles_name}.sdf\", None)\n",
    "        # extract features from sdf.\n",
    "        try:\n",
    "            compound_dict[smiles_name] = extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)  # self-dock set has_LAS_mask to true\n",
    "        except Exception as e:\n",
    "            print(smiles_name, e)\n",
    "            skip_smiles_list.append(smiles_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f028c",
   "metadata": {},
   "source": [
    "```\n",
    "skip_smiles_list = ['smiles_5544', 'smiles_39785', 'smiles_39786', 'smiles_39787', 'smiles_39788', 'smiles_40760', 'smiles_40762', 'smiles_40763', 'smiles_40764', 'smiles_40766', 'smiles_43789']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ebf656",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    torch.save(compound_dict, f\"/home/jovyan/dataspace/Prototype/dicts/FULL_compound_torchdrug_features.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "516ce02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    multiton_table = multiton_table[~multiton_table.kekule_smiles_name.isin(skip_smiles_list)]\n",
    "    multiton_table.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f1a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90545/3151936896.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/multiton_table_v2.csv\", index_col=0)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    multiton_table = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_multiton_table_v2.csv\", index_col=0)\n",
    "    multiton_table['session_aus'] = multiton_table['session_au'] + \"_\" + multiton_table['kekule_smiles']\n",
    "    data = multiton_table.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e7860",
   "metadata": {},
   "source": [
    "### 「折叠」表格处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9568c34a",
   "metadata": {},
   "source": [
    "#### 「折叠」导入分组文件以进行 `train-ood-iid-val` 分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39af2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    drugood_split = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/non_drugood_split2.csv\")\n",
    "    drugood_split=drugood_split.fillna(\"-\")\n",
    "    drugood_split.split_tag = drugood_split.split_tag.apply(lambda x: \"train\" if x==\"-\" else x)\n",
    "    drugood_split[\"session_aus\"] = drugood_split['assay_id'].astype(str) + \"_\" + drugood_split['uniprot_id'] + \"_\" + drugood_split['kekule_smiles']\n",
    "    drugood_split=drugood_split[['session_aus', 'split_tag']]\n",
    "    \n",
    "    data = pd.merge(left=multiton_table, right=drugood_split, how=\"left\", on=\"session_aus\")\n",
    "    data.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638993c",
   "metadata": {},
   "source": [
    "#### 「折叠」读取 `raw_info.csv` 为 `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1cac7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    data = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af698f",
   "metadata": {},
   "source": [
    "#### 「折叠」处理`data`生成 `info` 并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e52a5d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f872174b49d2493fbd6a8313a2159766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/695316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5886176\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    info = []\n",
    "    err_pdb_list=[]\n",
    "    for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        \n",
    "        sample_id = line['sample_id']\n",
    "        pdb_id = line['pdb_id']\n",
    "        uniprot_id = line['uniprot_id']\n",
    "        assay_id = line['assay_id']\n",
    "        smiles_name = line['kekule_smiles_name']\n",
    "        smiles = line['kekule_smiles']\n",
    "        session_au = line['session_au']\n",
    "        session_aus = line['session_aus']\n",
    "        \n",
    "        value = line['value']\n",
    "        docking_score = line['docking_score']\n",
    "        mmgbsa_binding_energy = line['mmgbsa_binding_energy']\n",
    "        qed = line[\"qed\"]\n",
    "        \n",
    "        split_tag = line['split_tag']\n",
    "        \n",
    "        protein_name = pdb_id.lower()\n",
    "        try:\n",
    "            pocket = pockets_dict[protein_name].head(20)\n",
    "        except:\n",
    "            err_pdb_list.append(pdb)\n",
    "            continue\n",
    "        pocket.columns = pocket.columns.str.strip()\n",
    "        pocket_coms = pocket[['center_x', 'center_y', 'center_z']].values\n",
    "\n",
    "        # protein center as a block.\n",
    "        protein_com = protein_dict[protein_name][0].numpy().mean(axis=0).astype(float).reshape(1, 3)\n",
    "        info.append([sample_id, pdb_id, uniprot_id, assay_id, smiles_name, smiles, session_au, session_aus, protein_com, protein_name+\"_c\", \n",
    "                     value, docking_score, mmgbsa_binding_energy, qed, split_tag])\n",
    "        \n",
    "        for idx, pocket_line in pocket.iterrows():\n",
    "            pdb_idx = f\"{protein_name}_{idx}\"\n",
    "            info.append([sample_id, pdb_id, uniprot_id, assay_id, smiles_name, smiles, session_au, session_aus, pocket_coms[idx].reshape(1, 3), pdb_idx, \n",
    "                         value, docking_score, mmgbsa_binding_energy, qed, split_tag])\n",
    "            \n",
    "    info = pd.DataFrame(\n",
    "        info, \n",
    "        columns=['sample_id', 'pdb_id', 'uniprot_id', 'assay_id', 'smiles_name', 'kekule_smiles', 'session_au', 'session_aus', 'pocket_com', 'pocket_name', \n",
    "                 'value', 'docking_score','mmgbsa_binding_energy', 'qed', 'split_tag'])\n",
    "    print(len(info))\n",
    "\n",
    "\n",
    "    len(err_pdb_list)\n",
    "    # 0\n",
    "\n",
    "\n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63ceb9",
   "metadata": {},
   "source": [
    "#### 「折叠」读取 `info_all_pockets` 为 `info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e254a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc4fa2",
   "metadata": {},
   "source": [
    "#### 「折叠」使用此前生成的 `ligand_coor_dict` 来指定口袋，生成 `pdb_id_to_pocket_name_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b7e51f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    ligand_coor_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/ARC_ligand_coor_dict.pt\")\n",
    "    \n",
    "    \n",
    "    pdb_id_to_pocket_name_dict ={}\n",
    "    error_pdb_id_list = []\n",
    "    for PDB_id in tqdm(ligand_coor_dict, total=len(ligand_coor_dict)):\n",
    "        try:\n",
    "            pdb_id = PDB_id.lower()\n",
    "            ligand_center = ligand_coor_dict[PDB_id][0]\n",
    "            p2rankFile = f\"/home/jovyan/dataspace/Prototype/p2rank_results/{pdb_id}_protein.pdb_predictions.csv\"\n",
    "            pocket = pd.read_csv(p2rankFile)\n",
    "            pocket.columns = pocket.columns.str.strip()\n",
    "            pocket_coms = pocket[['center_x', 'center_y', 'center_z']].values\n",
    "            pocket_coms_with_center = np.concatenate([pocket_coms.mean(axis=0).reshape(1,3), pocket_coms])\n",
    "            pocket_names = [pdb_id + \"_c\"] + [pdb_id+\"_\"+str(i) for i in range(len(pocket_coms))]\n",
    "            right_ith = ((pocket_coms_with_center-ligand_center)**2).sum(axis=1).argmin()\n",
    "            right_name = pocket_names[right_ith]\n",
    "            pdb_id_to_pocket_name_dict[PDB_id] = right_name\n",
    "        except:\n",
    "            print(PDB_id, end = \" \")\n",
    "            error_pdb_id_list.append(PDB_id)\n",
    "            pdb_id_to_pocket_name_dict[PDB_id] = \"ERROR\"\n",
    "            \n",
    "    torch.save(pdb_id_to_pocket_name_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pdb_id_to_pocket_name_dict.pt\")\n",
    "    torch.save(error_pdb_id_list, \"/home/jovyan/dataspace/Prototype/dicts/FULL_pdb_id_to_pocket_name_error_list.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee25fa",
   "metadata": {},
   "source": [
    "#### 「折叠」读取`pdb_id_to_pocket_name_dict`，并结合 `info_all_pockets` 构造出仅保留单个 `pocket` 的 `info_core_pocket`。\n",
    "错误的蛋白因为已标注为 `ERROR`，会因为没有名为 `ERROR` 的口袋而被略去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7579f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pdb_id_to_pocket_name_dict = torch.load(\"/home/jovyan/dataspace/Prototype/pdb_id_to_pocket_name_dict.pt\")\n",
    "    info['p2rank_core_pocket'] = info.apply(lambda x: pdb_id_to_pocket_name_dict[x.pdb_id] == x.pocket_name, axis=1)\n",
    "    \n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_all_pockets_noted.csv\")\n",
    "    \n",
    "    info = info[info.p2rank_core_pocket==True] \n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULLRAW_info_core_pocket.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053c416d",
   "metadata": {},
   "source": [
    "#### 「折叠」读取 `info_core_pocket`，该表格被用于构建最终数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b35458",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/info_core_pocket.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa97cab",
   "metadata": {},
   "source": [
    "针对 `val / test` 组的数据，额外提供一个根据 docking_score 预先指定口袋的 info_val_test_best_docking_score\n",
    "\n",
    "这一步在后续构建两个数据集时也进行了，所以可以不管这一格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "351669e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pandas import DataFrame\n",
    "    info_val_test = info[info.split_tag!=\"train\"]\n",
    "    info_val_test = info_val_test.sort_values('docking_score').groupby('session_aus').apply(DataFrame.head, n=1).reset_index(drop=True)\n",
    "    info_val_test.to_csv(\"/home/jovyan/dataspace/Prototype/tables/info_extra_for_val_and_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5632b3",
   "metadata": {},
   "source": [
    "针对 info 和 info_val_test 进行额外的 session_au_usability_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f9541fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    info_count = info[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    info_count.reset_index(inplace=True)\n",
    "    info_singleton = list(info_count[info_count.kekule_smiles==1].session_au)\n",
    "    info_multiton = list(info_count[info_count.kekule_smiles!=1].session_au)\n",
    "    ms_dict ={_:\"singleton\" for _ in info_singleton}\n",
    "    ms_dict.update({_:\"multiton\" for _ in info_multiton})\n",
    "    info['session_au_usability'] = info.session_au.apply(lambda x: ms_dict[x])\n",
    "    info = info[info.session_au_usability==\"multiton\"]\n",
    "    info.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.csv\")\n",
    "    info.to_pickle(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b64e1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    info_count = info_val_test[['session_au', 'kekule_smiles', 'pdb_id']].groupby('session_au').nunique()\n",
    "    info_count.reset_index(inplace=True)\n",
    "    info_singleton = list(info_count[info_count.kekule_smiles==1].session_au)\n",
    "    info_multiton = list(info_count[info_count.kekule_smiles!=1].session_au)\n",
    "    ms_dict ={_:\"singleton\" for _ in info_singleton}\n",
    "    ms_dict.update({_:\"multiton\" for _ in info_multiton})\n",
    "    info_val_test['session_au_usability'] = info_val_test.session_au.apply(lambda x: ms_dict[x])\n",
    "    info_val_test = info_val_test[info_val_test.session_au_usability==\"multiton\"]\n",
    "    info_val_test.to_csv(\"/home/jovyan/dataspace/Prototype/tables/info_extra_for_val_and_test_multiton.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc31638",
   "metadata": {},
   "source": [
    "### <font color='gold'>「从这里开始」</font>数据集构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd3830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "pdbbind_path = \"/home/jovyan/dataspace/PDBbind2020/all_pdbbind\"\n",
    "proto_path = \"/home/jovyan/dataspace/Prototype\"\n",
    "p2rank = \"bash /home/jovyan/TankBind/p2rank_2.3/prank\"\n",
    "tankbind_src_folder_path = \"../tankbind_prototype/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0aaf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tankbind_data_path = f\"/home/jovyan/dataspace/Prototype/tankbind_data\"\n",
    "protein_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_protein_dict.pt\")\n",
    "compound_dict = torch.load(\"/home/jovyan/dataspace/Prototype/dicts/FULL_compound_torchdrug_features.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5730d918",
   "metadata": {},
   "source": [
    "读取 `info` 并处理 `pocket_com` 列：该列在导出 `csv` 时会变成奇怪的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fcea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_pickle(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6c8d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/data.pt', '/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/protein.pt', '/home/jovyan/main_tankbind/dataset_prototype/full/dataset/processed/compound.pt']\n"
     ]
    }
   ],
   "source": [
    "from data_prototype import TankBindDataSet_prototype\n",
    "\n",
    "toFileFull = f\"/home/jovyan/main_tankbind/dataset_prototype/full/dataset\"\n",
    "os.system(f\"rm -rf {toFileFull}\")\n",
    "os.system(f\"mkdir -p {toFileFull}\")\n",
    "dataset = TankBindDataSet_prototype(toFileFull, data=info, protein_dict=protein_dict, compound_dict=compound_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e832c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb0044392c94e3c92652cfe62d97d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/691468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = []\n",
    "t_dict = {}\n",
    "data = dataset.data\n",
    "\n",
    "for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    d = dataset[i]\n",
    "    sample_id = line['sample_id']\n",
    "    p_length = d['node_xyz'].shape[0]\n",
    "    c_length = d['coords'].shape[0]\n",
    "    y_length = d['y'].shape[0]\n",
    "    t.append([i, sample_id, p_length, c_length, y_length])\n",
    "    t_dict[sample_id] = [i, sample_id, p_length, c_length, y_length]\n",
    "    \n",
    "torch.save(t, \"/home/jovyan/dataspace/Prototype/tables/FULL_supplementary.pt\")\n",
    "torch.save(t_dict, \"/home/jovyan/dataspace/Prototype/dicts/FULL_supplementary_dict.pt\")\n",
    "\n",
    "t = pd.DataFrame(t, columns=['index', 'sample_id', 'p_length', 'c_length', 'y_length'])\n",
    "t.to_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_supplementary.csv\")\n",
    "\n",
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87a5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.data\n",
    "t = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_t.csv\", index_col=0)\n",
    "data =pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350acb7",
   "metadata": {},
   "source": [
    "### 验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f221d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(\"/home/jovyan/dataspace/Prototype/tables/FULL_info_core_pocket_multiton.csv\", index_col=0)\n",
    "info.reset_index(inplace=True, drop=True)\n",
    "info.pocket_com = info.pocket_com.apply(lambda x: np.array([float(_) for _ in x.replace(\"[[\", \"\").replace(\"]]\", \"\").split()]))\n",
    "info2 = info[info.split_tag.isin([\"test\", 'iid_val', 'ood_val'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f055b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "info3 = info2.sort_values(by='docking_score', ascending=True).groupby('session_aus', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023cd935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_aus</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>assay_id</th>\n",
       "      <th>smiles_name</th>\n",
       "      <th>kekule_smiles</th>\n",
       "      <th>session_au</th>\n",
       "      <th>pocket_com</th>\n",
       "      <th>pocket_name</th>\n",
       "      <th>value</th>\n",
       "      <th>docking_score</th>\n",
       "      <th>mmgbsa_binding_energy</th>\n",
       "      <th>qed</th>\n",
       "      <th>split_tag</th>\n",
       "      <th>p2rank_core_pocket</th>\n",
       "      <th>session_au_usability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101008_Q13093_CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)...</td>\n",
       "      <td>ID_40414</td>\n",
       "      <td>5LP1</td>\n",
       "      <td>Q13093</td>\n",
       "      <td>101008</td>\n",
       "      <td>smiles_5980</td>\n",
       "      <td>CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)(F)F)C=C2)C=C1...</td>\n",
       "      <td>101008_Q13093</td>\n",
       "      <td>[28.8894, -27.5758, 4.0971]</td>\n",
       "      <td>5lp1_0</td>\n",
       "      <td>38.00</td>\n",
       "      <td>-10.430974</td>\n",
       "      <td>-77.290802</td>\n",
       "      <td>0.091834</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101008_Q13093_CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)...</td>\n",
       "      <td>ID_40428</td>\n",
       "      <td>5LP1</td>\n",
       "      <td>Q13093</td>\n",
       "      <td>101008</td>\n",
       "      <td>smiles_5987</td>\n",
       "      <td>CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)(F)F)C=C2)C=C1...</td>\n",
       "      <td>101008_Q13093</td>\n",
       "      <td>[28.8894, -27.5758, 4.0971]</td>\n",
       "      <td>5lp1_0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-11.782041</td>\n",
       "      <td>-87.809654</td>\n",
       "      <td>0.078839</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101009_Q13093_CC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=...</td>\n",
       "      <td>ID_40438</td>\n",
       "      <td>5I9I</td>\n",
       "      <td>Q13093</td>\n",
       "      <td>101009</td>\n",
       "      <td>smiles_5993</td>\n",
       "      <td>CC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=C(CC4=CN(C)N=C...</td>\n",
       "      <td>101009_Q13093</td>\n",
       "      <td>[202.0249, 27.3233, 114.6355]</td>\n",
       "      <td>5i9i_0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-8.839718</td>\n",
       "      <td>-103.795174</td>\n",
       "      <td>0.157879</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101009_Q13093_COC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C...</td>\n",
       "      <td>ID_40457</td>\n",
       "      <td>5I9I</td>\n",
       "      <td>Q13093</td>\n",
       "      <td>101009</td>\n",
       "      <td>smiles_6008</td>\n",
       "      <td>COC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=C(CC4=CN(C)N=...</td>\n",
       "      <td>101009_Q13093</td>\n",
       "      <td>[202.0249, 27.3233, 114.6355]</td>\n",
       "      <td>5i9i_0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>-9.582510</td>\n",
       "      <td>-103.853333</td>\n",
       "      <td>0.151225</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101941_P08254_COC(=O)CN1CCCC[C@H](NC(=O)[C@H](...</td>\n",
       "      <td>ID_40519</td>\n",
       "      <td>1BIW</td>\n",
       "      <td>P08254</td>\n",
       "      <td>101941</td>\n",
       "      <td>smiles_6046</td>\n",
       "      <td>COC(=O)CN1CCCC[C@H](NC(=O)[C@H](CC(C)C)[C@@H](...</td>\n",
       "      <td>101941_P08254</td>\n",
       "      <td>[-3.0935, 50.0764, 50.2571]</td>\n",
       "      <td>1biw_1</td>\n",
       "      <td>215.00</td>\n",
       "      <td>-6.442581</td>\n",
       "      <td>-33.285923</td>\n",
       "      <td>0.316662</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32626</th>\n",
       "      <td>992786_Q96KQ7_COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(...</td>\n",
       "      <td>ID_378564</td>\n",
       "      <td>3RJW</td>\n",
       "      <td>Q96KQ7</td>\n",
       "      <td>992786</td>\n",
       "      <td>smiles_55762</td>\n",
       "      <td>COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(N3CCC(F)(F)CC3...</td>\n",
       "      <td>992786_Q96KQ7</td>\n",
       "      <td>[-8.5015, 5.081, 47.7921]</td>\n",
       "      <td>3rjw_4</td>\n",
       "      <td>110.00</td>\n",
       "      <td>-10.620724</td>\n",
       "      <td>-94.102745</td>\n",
       "      <td>0.416893</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32627</th>\n",
       "      <td>992787_Q96KQ7_COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(...</td>\n",
       "      <td>ID_378587</td>\n",
       "      <td>3RJW</td>\n",
       "      <td>Q96KQ7</td>\n",
       "      <td>992787</td>\n",
       "      <td>smiles_55768</td>\n",
       "      <td>COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(C3CCOCC3)N=C2C...</td>\n",
       "      <td>992787_Q96KQ7</td>\n",
       "      <td>[-8.5015, 5.081, 47.7921]</td>\n",
       "      <td>3rjw_4</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>-10.248228</td>\n",
       "      <td>-87.341965</td>\n",
       "      <td>0.391258</td>\n",
       "      <td>iid_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32628</th>\n",
       "      <td>99805_P03372_CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(O...</td>\n",
       "      <td>ID_40352</td>\n",
       "      <td>2IOG</td>\n",
       "      <td>P03372</td>\n",
       "      <td>99805</td>\n",
       "      <td>smiles_4812</td>\n",
       "      <td>CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(OCCN3CCCCC3)C=...</td>\n",
       "      <td>99805_P03372</td>\n",
       "      <td>[32.2618, -0.7075, 26.0667]</td>\n",
       "      <td>2iog_1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-11.313963</td>\n",
       "      <td>-82.996925</td>\n",
       "      <td>0.361286</td>\n",
       "      <td>ood_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32629</th>\n",
       "      <td>99805_P03372_CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(O...</td>\n",
       "      <td>ID_40353</td>\n",
       "      <td>2IOG</td>\n",
       "      <td>P03372</td>\n",
       "      <td>99805</td>\n",
       "      <td>smiles_4813</td>\n",
       "      <td>CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(OCCN3CCCCCC3)C...</td>\n",
       "      <td>99805_P03372</td>\n",
       "      <td>[32.2618, -0.7075, 26.0667]</td>\n",
       "      <td>2iog_1</td>\n",
       "      <td>3.70</td>\n",
       "      <td>-11.228383</td>\n",
       "      <td>-76.889290</td>\n",
       "      <td>0.331311</td>\n",
       "      <td>ood_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32630</th>\n",
       "      <td>99805_P03372_O=C(C1=CC=C(OCCN2CCCCC2)C=C1)C1=C...</td>\n",
       "      <td>ID_40357</td>\n",
       "      <td>2R6W</td>\n",
       "      <td>P03372</td>\n",
       "      <td>99805</td>\n",
       "      <td>smiles_4787</td>\n",
       "      <td>O=C(C1=CC=C(OCCN2CCCCC2)C=C1)C1=C(C2=CC=C(O)C=...</td>\n",
       "      <td>99805_P03372</td>\n",
       "      <td>[13.1271, 52.6188, 60.4584]</td>\n",
       "      <td>2r6w_1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-12.213146</td>\n",
       "      <td>-95.670067</td>\n",
       "      <td>0.318664</td>\n",
       "      <td>ood_val</td>\n",
       "      <td>True</td>\n",
       "      <td>multiton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32631 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             session_aus  sample_id pdb_id  \\\n",
       "0      101008_Q13093_CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)...   ID_40414   5LP1   \n",
       "1      101008_Q13093_CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)...   ID_40428   5LP1   \n",
       "2      101009_Q13093_CC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=...   ID_40438   5I9I   \n",
       "3      101009_Q13093_COC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C...   ID_40457   5I9I   \n",
       "4      101941_P08254_COC(=O)CN1CCCC[C@H](NC(=O)[C@H](...   ID_40519   1BIW   \n",
       "...                                                  ...        ...    ...   \n",
       "32626  992786_Q96KQ7_COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(...  ID_378564   3RJW   \n",
       "32627  992787_Q96KQ7_COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(...  ID_378587   3RJW   \n",
       "32628  99805_P03372_CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(O...   ID_40352   2IOG   \n",
       "32629  99805_P03372_CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(O...   ID_40353   2IOG   \n",
       "32630  99805_P03372_O=C(C1=CC=C(OCCN2CCCCC2)C=C1)C1=C...   ID_40357   2R6W   \n",
       "\n",
       "      uniprot_id  assay_id   smiles_name  \\\n",
       "0         Q13093    101008   smiles_5980   \n",
       "1         Q13093    101008   smiles_5987   \n",
       "2         Q13093    101009   smiles_5993   \n",
       "3         Q13093    101009   smiles_6008   \n",
       "4         P08254    101941   smiles_6046   \n",
       "...          ...       ...           ...   \n",
       "32626     Q96KQ7    992786  smiles_55762   \n",
       "32627     Q96KQ7    992787  smiles_55768   \n",
       "32628     P03372     99805   smiles_4812   \n",
       "32629     P03372     99805   smiles_4813   \n",
       "32630     P03372     99805   smiles_4787   \n",
       "\n",
       "                                           kekule_smiles     session_au  \\\n",
       "0      CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)(F)F)C=C2)C=C1...  101008_Q13093   \n",
       "1      CCN(CC)CCN(CC1=CC=C(C2=CC=C(C(F)(F)F)C=C2)C=C1...  101008_Q13093   \n",
       "2      CC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=C(CC4=CN(C)N=C...  101009_Q13093   \n",
       "3      COC1=CC=C(C2=CC=C(CN(C)C(=O)CN3C=C(CC4=CN(C)N=...  101009_Q13093   \n",
       "4      COC(=O)CN1CCCC[C@H](NC(=O)[C@H](CC(C)C)[C@@H](...  101941_P08254   \n",
       "...                                                  ...            ...   \n",
       "32626  COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(N3CCC(F)(F)CC3...  992786_Q96KQ7   \n",
       "32627  COC1=CC2=C(NC3CCN(C(C)C)CC3)N=C(C3CCOCC3)N=C2C...  992787_Q96KQ7   \n",
       "32628  CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(OCCN3CCCCC3)C=...   99805_P03372   \n",
       "32629  CC1=C(C2=CC=C(O)C=C2)N(CC2=CC=C(OCCN3CCCCCC3)C...   99805_P03372   \n",
       "32630  O=C(C1=CC=C(OCCN2CCCCC2)C=C1)C1=C(C2=CC=C(O)C=...   99805_P03372   \n",
       "\n",
       "                          pocket_com pocket_name     value  docking_score  \\\n",
       "0        [28.8894, -27.5758, 4.0971]      5lp1_0     38.00     -10.430974   \n",
       "1        [28.8894, -27.5758, 4.0971]      5lp1_0      0.80     -11.782041   \n",
       "2      [202.0249, 27.3233, 114.6355]      5i9i_0      0.90      -8.839718   \n",
       "3      [202.0249, 27.3233, 114.6355]      5i9i_0     17.00      -9.582510   \n",
       "4        [-3.0935, 50.0764, 50.2571]      1biw_1    215.00      -6.442581   \n",
       "...                              ...         ...       ...            ...   \n",
       "32626      [-8.5015, 5.081, 47.7921]      3rjw_4    110.00     -10.620724   \n",
       "32627      [-8.5015, 5.081, 47.7921]      3rjw_4  50000.00     -10.248228   \n",
       "32628    [32.2618, -0.7075, 26.0667]      2iog_1      1.50     -11.313963   \n",
       "32629    [32.2618, -0.7075, 26.0667]      2iog_1      3.70     -11.228383   \n",
       "32630    [13.1271, 52.6188, 60.4584]      2r6w_1      0.72     -12.213146   \n",
       "\n",
       "       mmgbsa_binding_energy       qed split_tag  p2rank_core_pocket  \\\n",
       "0                 -77.290802  0.091834   iid_val                True   \n",
       "1                 -87.809654  0.078839   iid_val                True   \n",
       "2                -103.795174  0.157879   iid_val                True   \n",
       "3                -103.853333  0.151225   iid_val                True   \n",
       "4                 -33.285923  0.316662   iid_val                True   \n",
       "...                      ...       ...       ...                 ...   \n",
       "32626             -94.102745  0.416893   iid_val                True   \n",
       "32627             -87.341965  0.391258   iid_val                True   \n",
       "32628             -82.996925  0.361286   ood_val                True   \n",
       "32629             -76.889290  0.331311   ood_val                True   \n",
       "32630             -95.670067  0.318664   ood_val                True   \n",
       "\n",
       "      session_au_usability  \n",
       "0                 multiton  \n",
       "1                 multiton  \n",
       "2                 multiton  \n",
       "3                 multiton  \n",
       "4                 multiton  \n",
       "...                    ...  \n",
       "32626             multiton  \n",
       "32627             multiton  \n",
       "32628             multiton  \n",
       "32629             multiton  \n",
       "32630             multiton  \n",
       "\n",
       "[32631 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d0b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "info3.to_pickle(\"/home/jovyan/dataspace/Prototype/tables/EXTRA_info_sole_pdb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5659dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_pdbs = [_.lower() for _ in info2.pdb_id.unique()]\n",
    "small_smiles = list(info2.smiles_name.unique())\n",
    "\n",
    "protein_dict2 = {_:protein_dict[_] for _ in small_pdbs}\n",
    "compound_dict2 = {_:compound_dict[_] for _ in small_smiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d785bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/data.pt', '/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/protein.pt', '/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130/processed/compound.pt']\n"
     ]
    }
   ],
   "source": [
    "toFileExtra = f\"/home/jovyan/main_tankbind/dataset_prototype/extra_val_test_reduced_0130\"\n",
    "os.system(f\"rm -rf {toFileExtra}\")\n",
    "os.system(f\"mkdir -p {toFileExtra}\")\n",
    "\n",
    "from data_prototype import TankBindDataSet_prototype\n",
    "dataset = TankBindDataSet_prototype(toFileExtra, data=info3, protein_dict=protein_dict2, compound_dict=compound_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b630723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7925bee3c6a40d884281881cc22ed5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32631 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = []\n",
    "t_dict = {}\n",
    "data = dataset.data\n",
    "\n",
    "for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    d = dataset[i]\n",
    "    sample_id = line['sample_id']\n",
    "    p_length = d['node_xyz'].shape[0]\n",
    "    c_length = d['coords'].shape[0]\n",
    "    y_length = d['y'].shape[0]\n",
    "    t.append([i, sample_id, p_length, c_length, y_length])\n",
    "    t_dict[sample_id] = [i, sample_id, p_length, c_length, y_length]\n",
    "    \n",
    "torch.save(t, \"/home/jovyan/dataspace/Prototype/tables/EXTRA_supplementary.pt\")\n",
    "torch.save(t_dict, \"/home/jovyan/dataspace/Prototype/dicts/EXTRA_supplementary_dict.pt\")\n",
    "\n",
    "t = pd.DataFrame(t, columns=['index', 'sample_id', 'p_length', 'c_length', 'y_length'])\n",
    "t.to_csv(\"/home/jovyan/dataspace/Prototype/tables/EXTRA_supplementary.csv\")\n",
    "\n",
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileExtra}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c9743",
   "metadata": {},
   "source": [
    "t = []\n",
    "t_dict = {}\n",
    "data = dataset.data\n",
    "\n",
    "for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    d = dataset[i]\n",
    "    sample_id = line['sample_id']\n",
    "    p_length = d['node_xyz'].shape[0]\n",
    "    c_length = d['coords'].shape[0]\n",
    "    y_length = d['y'].shape[0]\n",
    "    t.append([i, sample_id, p_length, c_length, y_length])\n",
    "    t_dict[sample_id] = [i, sample_id, p_length, c_length, y_length]\n",
    "    \n",
    "torch.save(t, \"/home/jovyan/dataspace/Prototype/tables/full_t.pt\")\n",
    "torch.save(t_dict, \"/home/jovyan/dataspace/Prototype/tables/full_t_dict.pt\")\n",
    "\n",
    "t = pd.DataFrame(t, columns=['index', 'sample_id', 'p_length', 'c_length', 'y_length'])\n",
    "t.to_csv(\"/home/jovyan/dataspace/Prototype/tables/full_t.csv\")\n",
    "\n",
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length']]], axis=1)\n",
    "torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e6217",
   "metadata": {},
   "source": [
    "torch.save(data, f\"{toFileFull}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b293a0",
   "metadata": {},
   "source": [
    "dataset = TankBindDataSet_prototype(toFileFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19f7d9",
   "metadata": {},
   "source": [
    "t = []\n",
    "data = dataset.data\n",
    "pre_pdb = None\n",
    "for i, line in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    pdb = line['compound_name']\n",
    "    d = dataset[i]\n",
    "    p_length = d['node_xyz'].shape[0]\n",
    "    c_length = d['coords'].shape[0]\n",
    "    y_length = d['y'].shape[0]\n",
    "    num_contact = (d.y > 0).sum()\n",
    "    t.append([i, pdb, p_length, c_length, y_length, num_contact])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a762049",
   "metadata": {},
   "source": [
    "t = pd.DataFrame(t, columns=['index', 'pdb' ,'p_length', 'c_length', 'y_length', 'num_contact'])\n",
    "t['num_contact'] = t['num_contact'].apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e87efd",
   "metadata": {},
   "source": [
    "data = pd.concat([data, t[['p_length', 'c_length', 'y_length', 'num_contact']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def735d",
   "metadata": {},
   "source": [
    "native_num_contact = data.query(\"use_compound_com\").set_index(\"protein_name\")['num_contact'].to_dict()\n",
    "data['native_num_contact'] = data.protein_name.map(native_num_contact)\n",
    "# data['fract_of_native_contact'] = data['num_contact'] / data['native_num_contact']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30e3df",
   "metadata": {},
   "source": [
    "torch.save(data, f\"{toFilePre}/processed/data.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2dd0c",
   "metadata": {},
   "source": [
    "toFilePre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71c891",
   "metadata": {},
   "source": [
    "import torch\n",
    "info = torch.load(f\"{toFilePre}/processed/data.pt\")\n",
    "info['group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb9013f",
   "metadata": {},
   "source": [
    "test = info.query(\"group == 'test'\").reset_index(drop=True)\n",
    "test_pdb_list = info.query(\"group == 'test'\").protein_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd941c",
   "metadata": {},
   "source": [
    "test = info.query(\"group == 'test'\").reset_index(drop=True)\n",
    "test_pdb_list = info.query(\"group == 'test'\").protein_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f37fba",
   "metadata": {},
   "source": [
    "subset_protein_dict = {}\n",
    "for pdb in tqdm(test_pdb_list):\n",
    "    subset_protein_dict[pdb] = protein_dict[pdb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4fe83",
   "metadata": {},
   "source": [
    "subset_compound_dict = {}\n",
    "for pdb in tqdm(test_pdb_list):\n",
    "    subset_compound_dict[pdb] = compound_dict[pdb]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b5227",
   "metadata": {},
   "source": [
    "\n",
    "toFilePre = f\"{pre}/test_dataset\"\n",
    "os.system(f\"mkdir -p {toFilePre}\")\n",
    "dataset = TankBindDataSet(toFilePre, data=test, protein_dict=subset_protein_dict, compound_dict=subset_compound_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a7cb4f",
   "metadata": {},
   "source": [
    "def canonical_smiles(smiles):\n",
    "    return Chem.MolToSmiles(Chem.MolFromSmiles(smiles))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
