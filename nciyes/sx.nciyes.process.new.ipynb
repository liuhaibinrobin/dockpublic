{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# sx.nciyes.process.<font color=\"red\">new</font>.ipynb\n",
    "\n",
    "Notebook for processing input datas.\n",
    "New nci data will be used.\n",
    "Data in <font color=\"red\">data/HBPDB/Ligand</font> and <font color=\"red\">data/pdbbind2020/</font> are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "version = \"v9.1\" \n",
    "mode_ls = [\"tankbind\", \"nciyes\", \"frag\"]\n",
    "cfg_mode = \"tankbind\"\n",
    "\n",
    "# You needn't modify the settings below under normal conditions.\n",
    "save_path = f\"./Inputs/{cfg_mode}/{version}/\"\n",
    "os.system(f\"mkdir -p {save_path}\")\n",
    "\n",
    "nci_path = \"../../dataspace/pdb_bind_2020/\"\n",
    "nci_data_fpath = \"../../dataspace/exptnci_220825.csv\"\n",
    "\n",
    "refined_path = \"../../data/pdbbind2020/refined-set/\" # for .pdb files\n",
    "general_path = \"../../data/pdbbind2020/v2020-other-PL/\"\n",
    "\n",
    "\n",
    "\n",
    "refined_affinity_fpath = \"../../data/pdbbind2020/index/INDEX_refined_data_preprocessed.2020\"\n",
    "general_affinity_fpath = \"../../data/pdbbind2020/index/INDEX_general_PL_data_preprocessed.2020\"\n",
    "refined_aff_df_fpath = refined_affinity_fpath + \".csv\"\n",
    "general_aff_df_fpath = general_affinity_fpath + \".csv\"\n",
    "\n",
    "\n",
    "R = \"\\033[1;31m\"\n",
    "B = \"\\033[1;34m\"\n",
    "S = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Manually modification record\n",
    "\n",
    "PL otherï¼š\n",
    "- Rename the columns : PDB, resolution, release_year, -logKd/Ki,Kd/Ki, reference, ligand_name\n",
    "- Rename ligand name \"FMN hq\", \"FMN sq\", \"FMN ox\", ... to \"FMN-hq\", \"FMN-sq\", \"FMN-ox\"\n",
    "- Remove \"(\", \")\", \"//\"\n",
    "- Line 5512 (p 5507): from \"5ot3  2.04  2018   5.23  Kd=5.86uM     5ot3.pdf 9LQ,18-mer\" to \"9LQ/18-mer\"\n",
    "- Save modified file to \"INDEX_general_PL_data_preprocessed.2020\"\n",
    "    \n",
    "\n",
    "refined:\n",
    "- Rename the columns : PDB, resolution, release_year, -logKd/Ki,Kd/Ki, reference, ligand_name\n",
    "- Remove \"(\", \")\", \"//\"\n",
    "- Save modified file to \"INDEX_refined_data_preprocessed.2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Affinity files generation and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Generation\n",
    "    for _dpath,_folder in zip([refined_affinity_fpath, general_affinity_fpath], [refined_path, general_path]):\n",
    "        if True:\n",
    "            #print(_dpath)\n",
    "            os.system(f\"rm {_dpath}.csv\")\n",
    "            ls = []\n",
    "            with open(f\"{_dpath}\", 'r') as f:\n",
    "                line = f.readline()\n",
    "                #print(line)\n",
    "                while line != \"\" or []:\n",
    "                    items = line.split()\n",
    "                    ls.append(items)\n",
    "                    line = f.readline()\n",
    "            columns = ls[0]\n",
    "            #print(ls[0])\n",
    "            del ls[0]\n",
    "            df = pd.DataFrame(ls, columns=columns)\n",
    "            df.to_csv(f\"{_dpath}.csv\")\n",
    "    # Check affinity\n",
    "    _aff = pd.read_csv(f\"{_dpath}.csv\", index_col=0)\n",
    "    _aff_pdbs = set(_aff.PDB_code.unique())\n",
    "    _folder_pdbs = np.array(os.listdir(_folder))\n",
    "    _folder_pdbs.sort()\n",
    "    for _f in _folder_pdbs:\n",
    "        if _f not in _aff_pdbs:\n",
    "            print(_f,\"has no affinity data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5316, 14127, 19443, 19443, 15189)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get PDB list\n",
    "refined_pdbs = set(os.listdir(refined_path))\n",
    "general_pdbs = set(os.listdir(general_path))\n",
    "all_pdbs = refined_pdbs|general_pdbs\n",
    "nci_pdbs = set(os.listdir(nci_path))\n",
    "len(refined_pdbs), len(general_pdbs), len(refined_pdbs) + len(general_pdbs), len(all_pdbs), len(nci_pdbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5316 pdbs in refined set and 14127 in general set. The two sets are disjoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Frag and tankband data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \u001b[1;34m.pdb\u001b[0m files for \u001b[1;31mrefined\u001b[0m:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b1e987bb36439bb72ecbd6ca1c767f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing \u001b[1;34m.pdb\u001b[0m files for \u001b[1;31mgeneral\u001b[0m:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc63fd0f8228479da59aedae201d14f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved \u001b[1;31mpdb_df\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Intermediate.v9.1.step_1_PDBs_19443 - With LigName.csv\u001b[0m\n",
      "Saved \u001b[1;31mligand_df\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Intermediate.v9.1.step_1_Ligands_19443 - With LigName.csv\u001b[0m\n",
      "Saved \u001b[1;31mdrop_1\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Removed.v9.1.step_1_PDBs_0 - Dropped with LigName Generation Error.csv\u001b[0m\n",
      "Saved \u001b[1;31mligand_coherent_df\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Data.v9.1.Ligands.csv\u001b[0m\n",
      "Saved \u001b[1;31mdrop_2: ligand with incoherent name\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Removed.v9.1.step_2_Ligands_3129 - Dropped with incoherent LigName.csv\u001b[0m\n",
      "Saved \u001b[1;31mpdb_coherent_df\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Data.v9.1.PDBs.csv\u001b[0m\n",
      "Saved \u001b[1;31mdrop_3: pdb with incoherent name\u001b[0m to \u001b[1;34m./Inputs/tankbind/v9.1/Removed.v9.1.step_2_PDBs_3129 - Dropped with incoherent LigName.csv\u001b[0m\n",
      "\n",
      "Processed files: \n",
      "\u001b[1;31mLigand\u001b[1;34m:    \u001b[1;34m./Inputs/tankbind/v9.1/Data.v9.1.Ligands.csv\u001b[0m   num: \u001b[1;31m16314\u001b[0m\n",
      "\u001b[1;31mProteins\u001b[1;34m:  \u001b[1;34m./Inputs/tankbind/v9.1/Data.v9.1.PDBs.csv\u001b[0m      num: \u001b[1;31m16314\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if cfg_mode == \"frag\" or cfg_mode == \"tankbind\":\n",
    "    from Bio.PDB import PDBParser\n",
    "    parser = PDBParser()\n",
    "    pdb_df_list = []\n",
    "    ligand_df_list = []\n",
    "    drop_4 = []\n",
    "\n",
    "    # refined\n",
    "    for (_name, _pdb_list, _pdb_path, _aff_fpath) in zip(\n",
    "        [\"refined\",\"general\"],[refined_pdbs, general_pdbs], [refined_path, general_path], [refined_aff_df_fpath, general_aff_df_fpath]\n",
    "        ):\n",
    "        print(f\"Processing {B}.pdb{S} files for {R}{_name}{S}:\")\n",
    "        aff_df = pd.read_csv(_aff_fpath, index_col=0)\n",
    "        for (i,_pdb) in enumerate(tqdm(_pdb_list, total=len(_pdb_list))):\n",
    "            with open(f\"{_pdb_path}{_pdb}/{_pdb}_ligand.mol2\") as f:\n",
    "                lines = f.readlines()\n",
    "                for i in range(len(lines)):\n",
    "                    if \"@<TRIPOS>ATOM\" in lines[i] and (i+1)< len(lines):\n",
    "                        ligand_name = lines[i+1].split()[-2]\n",
    "                        break\n",
    "                    ligand_name = \"ERROR\"\n",
    "                        \n",
    "            aff_line = aff_df[(aff_df[\"PDB_code\"]== _pdb)]\n",
    "            \n",
    "            if len(aff_line) == 1:\n",
    "                aff = aff_line[\"-logKd/Ki\"].values[0]\n",
    "                release_year = aff_line[\"release_year\"].values[0]\n",
    "                if not isinstance(aff, int) and not isinstance(aff, float):\n",
    "                    drop_4.append([_pdb, f\"{_pdb_path}{_pdb}/{_pdb}_ligand.sdf\", f\"Error with affinity data : {aff}\"])\n",
    "                    continue\n",
    "            else:\n",
    "                drop_4.append([_pdb, f\"{_pdb_path}{_pdb}/{_pdb}_ligand.sdf\", f\"Error with affinity data : {aff}\"])\n",
    "                continue\n",
    "            \n",
    "            ligand_name2 = aff_line['ligand_name'].values[0]\n",
    "            pdb_df_list.append([_pdb, f\"{_pdb_path}{_pdb}/{_pdb}_protein.sdf\", _name, release_year])\n",
    "            ligand_df_list.append([_pdb, ligand_name, ligand_name2, f\"{_pdb_path}{_pdb}/{_pdb}_ligand.sdf\", aff, _name, release_year])\n",
    "\n",
    "    pdb_df = pd.DataFrame(pdb_df_list, columns=[\"pdb_code\", \"pdb_fpath\", \"datagroup\", \"release_year\"])\n",
    "    _s = f\"{save_path}Intermediate.{version}.step_1_PDBs_{len(pdb_df)} - With LigName.csv\"\n",
    "    pdb_df.to_csv(_s)\n",
    "    print(f\"Saved {R}pdb_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    ligand_df = pd.DataFrame(ligand_df_list, columns=[\"pdb_code\", \"ligand_name_file\", \"ligand_name_aff\", \"ligand_fpath\", \"affinity\", \"datagroup\", \"release_year\"])\n",
    "    _s = f\"{save_path}Intermediate.{version}.step_1_Ligands_{len(pdb_df)} - With LigName.csv\"\n",
    "    ligand_df.to_csv(_s)\n",
    "    print(f\"Saved {R}ligand_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    drop_4 = pd.DataFrame(drop_4, columns=[\"pdb_code\", \"ligand_fpath\", \"error_info\"])\n",
    "    _s = f\"{save_path}Removed.{version}.step_1_PDBs_{len(drop_4)} - Dropped with LigName Generation Error.csv\"\n",
    "    drop_4.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_1{S} to {B}{_s}{S}\")\n",
    "    \n",
    "    ligand_coherent_df = ligand_df[(ligand_df[\"ligand_name_file\"]==ligand_df[\"ligand_name_aff\"])]\n",
    "    ligand_coherent_df = ligand_coherent_df.reset_index()\n",
    "    del ligand_coherent_df[\"index\"]\n",
    "    _s = f\"{save_path}Data.{version}.Ligands.csv\"\n",
    "    ligand_coherent_df.to_csv(_s)\n",
    "    print(f\"Saved {R}ligand_coherent_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    drop_5 = ligand_df[(ligand_df[\"ligand_name_file\"]!=ligand_df[\"ligand_name_aff\"])]\n",
    "    _s = f\"{save_path}Removed.{version}.step_2_Ligands_{len(drop_5)} - Dropped with incoherent LigName.csv\"\n",
    "    drop_5.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_2: ligand with incoherent name{S} to {B}{_s}{S}\")\n",
    "\n",
    "    pdb_coherent_df = pdb_df[~pdb_df.pdb_code.isin(drop_5.pdb_code.unique())].reset_index()\n",
    "    del pdb_coherent_df[\"index\"]\n",
    "    _s = f\"{save_path}Data.{version}.PDBs.csv\"\n",
    "    pdb_coherent_df.to_csv(_s)\n",
    "    print(f\"Saved {R}pdb_coherent_df{S} to {B}{_s}{S}\")\n",
    "    drop_6 = pdb_df[pdb_df.pdb_code.isin(drop_5.pdb_code.unique())]\n",
    "    _s = f\"{save_path}Removed.{version}.step_2_PDBs_{len(drop_6)} - Dropped with incoherent LigName.csv\"\n",
    "    drop_6.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_3: pdb with incoherent name{S} to {B}{_s}{S}\")\n",
    "\n",
    "    print(f\"\\nProcessed files: \")\n",
    "    _s = f\"{save_path}Data.{version}.Ligands.csv\"\n",
    "    print(f\"{R}Ligand{B}:    {B}{_s}{S}   num: {R}{len(pdb_coherent_df)}{S}\")\n",
    "    _s = f\"{save_path}Data.{version}.PDBs.csv\"\n",
    "    print(f\"{R}Proteins{B}:  {B}{_s}{S}      num: {R}{len(pdb_coherent_df)}{S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. NCI & PDB data initilization\n",
    "- Remove water group.\n",
    "- Remove insufficient resolution.\n",
    "- Remove wrong CP type, only (3,-1) will be kept.\n",
    "- Remove NCI with both negative EDs.\n",
    "- Remove empty ligatomname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    _logs = []\n",
    "    raw_nci_data = pd.read_csv(nci_data_fpath)\n",
    "    _a = len(raw_nci_data[raw_nci_data.Group==\"water\"])\n",
    "    _b = len(raw_nci_data[(raw_nci_data[\"ED_2A\"]<0)&(raw_nci_data[\"ED_3A\"]<0)])\n",
    "    _c = len(raw_nci_data[raw_nci_data[\"Resolution\"]>2.5])\n",
    "    _d = len(raw_nci_data[raw_nci_data.CP_type!=\"(3::-1)\"])\n",
    "    _logs.append(f\"Raw water: {_a}.\\n\")\n",
    "    _logs.append(f\"Raw both-negative EDs: {_b}.\\n\")\n",
    "    _logs.append(f\"Raw insufficient Resolution: {_c}.\\n\")\n",
    "    _logs.append(f\"Raw wrong CP_type: {_d}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    _num = len(raw_nci_data)\n",
    "    nci_data = raw_nci_data[raw_nci_data[\"Group\"]!=\"water\"]\n",
    "    _logs.append(f\"Remove water: {_num-len(nci_data)} removed, {len(nci_data)} remain.        -- (Group != water) kept.\\n\")\n",
    "\n",
    "    _num = len(nci_data)\n",
    "    nci_data = nci_data[(nci_data[\"ED_2A\"]>=0)|(nci_data[\"ED_3A\"]>=0)]\n",
    "    _logs.append(f\"Remove both-negative EDs: {_num-len(nci_data)} removed, {len(nci_data)} remain.        -- (ED_2A>=0 or ED_3A>=0) kept.\\n\")\n",
    "\n",
    "    _num = len(nci_data)\n",
    "    nci_data=nci_data[nci_data[\"Resolution\"]<=2.5]\n",
    "    _logs.append(f\"Remove insufficent Resolution: {_num-len(nci_data)} removed, {len(nci_data)} remain.         -- (Resolution<=2.5) kept.\\n\")\n",
    "\n",
    "    _num = len(nci_data)\n",
    "    nci_data[\"LigAtomName\"].fillna(0,inplace=True)\n",
    "    nci_data=nci_data[nci_data[\"LigAtomName\"]!=0]\n",
    "    _logs.append(f\"Remove empty LigAtomName: {_num-len(nci_data)} removed, {len(nci_data)} remain.         -- (LigAtomName is not NaN) kept.\\n\")      \n",
    "\n",
    "    _num = len(nci_data)\n",
    "    nci_data = nci_data[nci_data.CP_type == \"(3::-1)\"]\n",
    "    _logs.append(f\"Remove wrong CP_type: {_num-len(nci_data)} removed, {len(nci_data)} remain.         -- (CP_type == \\\"(3::-1)\\\") kept.\\n\")\n",
    "\n",
    "    # Add ResFullID\n",
    "    nci_data[\"ResFullID\"] = nci_data[\"ChainID\"]+\"_\"+nci_data[\"ResID\"].astype(str)+\"_\"+nci_data[\"ResName\"].astype(str)\n",
    "    _logs.append(\"Column ResFullID added.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(f\"{save_path}Removed.{version}.step_1_NCIs_{len(raw_nci_data)-len(nci_data)} - Initialization.txt\", \"w\") as f:\n",
    "        f.writelines(_logs)\n",
    "    nci_data.to_csv(f\"{save_path}Intermediate.{version}.step_1_NCIs_{len(nci_data)} - Initialized.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    # Remove ncis without pdbbind files\n",
    "    drop_1 = nci_data[~nci_data.PDB_Code.isin(all_pdbs)]\n",
    "    drop_1.to_csv(f\"{save_path}Removed.{version}.step_2_NCIs_{len(drop_1)} - Dropped without PDBBind files.csv\")\n",
    "\n",
    "    drop_2 = nci_data[~nci_data.PDB_Code.isin(nci_pdbs)]\n",
    "    drop_2.to_csv(f\"{save_path}Removed.{version}.step_3_NCIs_{len(drop_2)} - Dropped without ligand files.csv\")\n",
    "\n",
    "    nci_data = nci_data[(nci_data.PDB_Code.isin(all_pdbs))&(nci_data.PDB_Code.isin(nci_pdbs))]\n",
    "\n",
    "\n",
    "    # Check ncis\n",
    "    nci_pdbs = set(nci_data.PDB_Code.unique())\n",
    "    all_pdbs = refined_pdbs|general_pdbs\n",
    "    all_nci_pdbs = nci_pdbs.intersection(all_pdbs, nci_pdbs)\n",
    "    refined_nci_pdbs = refined_pdbs.intersection(all_nci_pdbs)\n",
    "    general_nci_pdbs = general_pdbs.intersection(all_nci_pdbs)\n",
    "\n",
    "\n",
    "    refined_without_nci_pdbs = refined_pdbs - refined_nci_pdbs\n",
    "    general_without_nci_pdbs = general_pdbs - general_nci_pdbs\n",
    "\n",
    "    nci_data = nci_data[nci_data.PDB_Code.isin(all_nci_pdbs)]\n",
    "    nci_data = nci_data.reset_index().rename(columns={\"index\":\"original_index\"})\n",
    "\n",
    "    drop_3 = [[_line, \"refined\"] for _line in refined_without_nci_pdbs]\n",
    "    drop_3.extend([[_line, \"general\"] for _line in general_without_nci_pdbs])\n",
    "    drop_3 = pd.DataFrame(drop_3, columns = [\"pdb_code\", \"pdb_group\"])\n",
    "    drop_3.to_csv(f\"{save_path}Removed.{version}.step_4_PDBs_{len(drop_3)} - Dropped without NCI.csv\")\n",
    "    nci_data.to_csv(f\"{save_path}Intermediate.{version}.step_4_NCIs_{len(nci_data)} - With Coherent Files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    # Check ligand name uniqueness for each pdb_code\n",
    "    nci_ligand_name_data = nci_data[[\"PDB_Code\", \"LigName\", \"LigAtomName\", \"ResFullID\", \"CP_type\", \"Group\"]]\n",
    "    nci_ligand_name_data = nci_ligand_name_data.groupby([\"PDB_Code\", \"LigName\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    len(nci_ligand_name_data['PDB_Code']), len(nci_ligand_name_data['PDB_Code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 10227 unique pdb_codes and 10227 rows, each pdb is related to a unique ligname in nci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ligand name coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    from Bio.PDB import PDBParser\n",
    "    parser = PDBParser()\n",
    "    pdb_df_list = []\n",
    "    ligand_df_list = []\n",
    "    drop_4 = []\n",
    "\n",
    "    # refined\n",
    "    for (_name, _pdb_list, _pdb_path, _aff_fpath) in zip(\n",
    "        [\"refined\",\"general\"],[refined_nci_pdbs, general_nci_pdbs], [refined_path, general_path], [refined_aff_df_fpath, general_aff_df_fpath]\n",
    "        ):\n",
    "        print(f\"Processing {B}.pdb{S} files for {R}{_name}{S}:\")\n",
    "        aff_df = pd.read_csv(_aff_fpath, index_col=0)\n",
    "        for (i,_pdb) in enumerate(tqdm(_pdb_list, total=len(_pdb_list))):\n",
    "            model = parser.get_structure(\"pdb\", f\"{nci_path}{_pdb}/{_pdb}_ligand.pdb\")[0]\n",
    "            ligand_name_set = set()\n",
    "            for _chain in model:\n",
    "                for _residue in _chain:\n",
    "                    ligand_name_set.add(_residue.get_full_id()[3][0])\n",
    "            if len(ligand_name_set) == 1:\n",
    "                ligand_name = list(ligand_name_set)[0].replace(\"H_\",\"\")\n",
    "            else:\n",
    "                drop_4.append([_pdb, f\"{nci_path}{_pdb}/{_pdb}_ligand.pdb\", f\"More than one ligand name : {str(ligand_name_set)}\"])\n",
    "                continue \n",
    "            \n",
    "            aff_line = aff_df[(aff_df[\"PDB_code\"]== _pdb)]\n",
    "            \n",
    "            if len(aff_line) == 1:\n",
    "                aff = aff_line[\"-logKd/Ki\"].values[0]\n",
    "                release_year = aff_line[\"release_year\"].values[0]\n",
    "                if not isinstance(aff, int) and not isinstance(aff, float):\n",
    "                    drop_4.append([_pdb, f\"{nci_path}{_pdb}/{_pdb}_ligand.pdb\", f\"Error with affinity data : {aff}\"])\n",
    "                    continue\n",
    "            else:\n",
    "                drop_4.append([_pdb, f\"{nci_path}{_pdb}/{_pdb}_ligand.pdb\", f\"Error with affinity data : {aff}\"])\n",
    "                continue\n",
    "            \n",
    "            ligand_name2 = aff_line['ligand_name'].values[0]\n",
    "            ligand_name3 = nci_data[(nci_data[\"PDB_Code\"]==_pdb)].LigName.unique().__str__().replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'\", \"\")\n",
    "            pdb_df_list.append([_pdb, f\"{_pdb_path}{_pdb}/{_pdb}_protein.pdb\", _name, release_year])\n",
    "            ligand_df_list.append([_pdb, ligand_name, ligand_name2, ligand_name3, f\"{nci_path}{_pdb}/{_pdb}_ligand.pdb\", aff, _name, release_year])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    pdb_df = pd.DataFrame(pdb_df_list, columns=[\"pdb_code\", \"pdb_fpath\", \"datagroup\", \"release_year\"])\n",
    "    _s = f\"{save_path}Intermediate.{version}.step_5_PDBs_{len(pdb_df)} - With LigName.csv\"\n",
    "    pdb_df.to_csv(_s)\n",
    "    print(f\"Saved {R}pdb_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    ligand_df = pd.DataFrame(ligand_df_list, columns=[\"pdb_code\", \"ligand_name_ncifile\", \"ligand_name_aff\", \"ligand_name_nci\", \"ligand_fpath\", \"affinity\", \"datagroup\", \"release_year\"])\n",
    "    _s = f\"{save_path}Intermediate.{version}.step_5_Ligands_{len(pdb_df)} - With LigName.csv\"\n",
    "    ligand_df.to_csv(_s)\n",
    "    print(f\"Saved {R}ligand_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    drop_4 = pd.DataFrame(drop_4, columns=[\"pdb_code\", \"ligand_fpath\", \"error_info\"])\n",
    "    _s = f\"{save_path}Removed.{version}.step_5_PDBs_{len(drop_4)} - Dropped with LigName Generation Error.csv\"\n",
    "    drop_4.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_4{S} to {B}{_s}{S}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_mode == \"nciyes\":\n",
    "    ligand_coherent_df = ligand_df[(ligand_df[\"ligand_name_ncifile\"]==ligand_df[\"ligand_name_aff\"])&(ligand_df[\"ligand_name_ncifile\"]==ligand_df[\"ligand_name_nci\"])]\n",
    "    ligand_coherent_df = ligand_coherent_df.reset_index()\n",
    "    del ligand_coherent_df[\"index\"]\n",
    "    _s = f\"{save_path}Data.{version}.Ligands.csv\"\n",
    "    ligand_coherent_df.to_csv(_s)\n",
    "    print(f\"Saved {R}ligand_coherent_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "    drop_5 = ligand_df[(ligand_df[\"ligand_name_ncifile\"]!=ligand_df[\"ligand_name_aff\"])|(ligand_df[\"ligand_name_ncifile\"]!=ligand_df[\"ligand_name_nci\"])]\n",
    "    _s = f\"{save_path}Removed.{version}.step_6_Ligands_{len(drop_5)} - Dropped with incoherent LigName.csv\"\n",
    "    drop_5.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_5: ligand with incoherent name{S} to {B}{_s}{S}\")\n",
    "\n",
    "    pdb_coherent_df = pdb_df[~pdb_df.pdb_code.isin(drop_5.pdb_code.unique())].reset_index()\n",
    "    del pdb_coherent_df[\"index\"]\n",
    "    _s = f\"{save_path}Data.{version}.PDBs.csv\"\n",
    "    pdb_coherent_df.to_csv(_s)\n",
    "    print(f\"Saved {R}pdb_coherent_df{S} to {B}{_s}{S}\")\n",
    "\n",
    "\n",
    "\n",
    "    drop_6 = pdb_df[pdb_df.pdb_code.isin(drop_5.pdb_code.unique())]\n",
    "    _s = f\"{save_path}Removed.{version}.step_6_PDBs_{len(drop_6)} - Dropped with incoherent LigName.csv\"\n",
    "    drop_6.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_6: pdb with incoherent name{S} to {B}{_s}{S}\")\n",
    "\n",
    "    nci_data_coherent = nci_data[~nci_data.PDB_Code.isin(drop_5.pdb_code.unique())].reset_index()\n",
    "    del nci_data_coherent[\"index\"]\n",
    "    _s = f\"{save_path}Data.{version}.NCIs.csv\"\n",
    "    nci_data_coherent.to_csv(_s)\n",
    "    print(f\"Saved {R}nci_data_coherent{S} to {B}{_s}{S}\")\n",
    "\n",
    "    drop_7 = nci_data[nci_data.PDB_Code.isin(drop_5.pdb_code.unique())]\n",
    "    _s = f\"{save_path}Removed.{version}.step_6_NCIs_{len(drop_7)} - Dropped with incoherent LigName.csv\"\n",
    "    drop_7.to_csv(_s)\n",
    "    print(f\"Saved {R}drop_7: NCI with incoherent name{S} to {B}{_s}{S}\")\n",
    "\n",
    "    with open(f\"{save_path}Datainfo.txt\", \"w\") as f:\n",
    "        f.write(f\"Data version: {version}\\n\")\n",
    "        f.write(f\"PDBs: {len(pdb_coherent_df)}, Ligands: {len(pdb_coherent_df)}, NCIs: {len(nci_data_coherent)}\")\n",
    "\n",
    "    print(f\"\\nProcessed files: \")\n",
    "    _s = f\"{save_path}Data.{version}.Ligands.csv\"\n",
    "    print(f\"{R}Ligand{B}:    {B}{_s}{S}   num: {R}{len(pdb_coherent_df)}{S}\")\n",
    "    _s = f\"{save_path}Data.{version}.PDBs.csv\"\n",
    "    print(f\"{R}Proteins{B}:  {B}{_s}{S}      num: {R}{len(pdb_coherent_df)}{S}\")\n",
    "    _s = f\"{save_path}Data.{version}.NCIs.csv\"\n",
    "    print(f\"{R}NCI Table{B}: {B}{_s}{S}      num: {R}{len(nci_data_coherent)}{S}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tankbind_py38]",
   "language": "python",
   "name": "conda-env-tankbind_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
