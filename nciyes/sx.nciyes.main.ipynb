{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23142276",
   "metadata": {
    "tags": []
   },
   "source": [
    "# sx.nciyes.main.ipynb\n",
    "\n",
    "Notebook for training and inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec45038",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "### Running Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c21caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_development = True # Whether the testing paths are used.\n",
    "cfg_use_nci = True # Temporarily unused.\n",
    "cfg_singleton = False # Whether only one protein is integrated.\n",
    "cfg_distinguish_by_timestamp = True # As name suggests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a832488",
   "metadata": {},
   "source": [
    "### Path Configuration\n",
    "Fill in the first block with paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05dd61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = None # Path to load all inputs.\n",
    "output_path = None # Path to store intermediate and final outputs. Each run creates a folder here.\n",
    "ds_path = None # Path to store .ds file for p2rank.\n",
    "\n",
    "log_path = \"./Logs/\" # Paht to store log files.\n",
    "p2rank_path = \"../p2rank_2.3/prank\" # Path of prank file.\n",
    "\n",
    "pdb_df_fname = None # Filename of protein info dataframe.\n",
    "ligand_df_fname = None # Filename of ligand info dataframe.\n",
    "pdb_df_fpath = None # Full path of protein info dataframe.\n",
    "ligand_df_fpath = None # Full path of ligand info dataframe.\n",
    "\n",
    "pdb_path = \"./Inputs/Dev/RenamedPDBBind/\" # Path to load all the .pdb files of proteins.\n",
    "ligand_path = \"./Inputs/Dev/RenamedPDBBind/\" # Path to load all the .mol2 files of ligands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edb375",
   "metadata": {},
   "source": [
    "#### <font color=\"grey\"><i>processing block</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c9f589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tankbind_src_folder_path = \"../tankbind/\"\n",
    "import sys\n",
    "sys.path.insert(0, tankbind_src_folder_path)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "# Development path settings.\n",
    "if cfg_development:\n",
    "    input_path = \"./Inputs/Dev/\"\n",
    "    output_path = \"./Outputs/Dev/\"\n",
    "    ds_path = \"../../../\"\n",
    "    pdb_df_fname = \"dev.pdbs.csv\"\n",
    "    ligand_df_fname = \"dev.ligands.csv\"\n",
    "    nci_fname = \"dev.nci.csv\"\n",
    "    pdb_df_fpath = \"./Inputs/Dev/dev.pdbs.csv\"\n",
    "    ligand_df_fpath = \"./Inputs/Dev/dev.ligands.csv\"\n",
    "\n",
    "# Path settings.\n",
    "if pdb_df_fname and not pdb_df_fpath:\n",
    "    pdb_df_fpath = f\"{input_path}{pdb_df_fname}\"\n",
    "if ligand_df_fname and not ligand_df_fpath:\n",
    "    ligand_df_fpath = f\"{input_path}{ligand_df_fname}\"\n",
    "pdb_df_fpath = f\"{input_path}{pdb_df_fname}\"\n",
    "ligand_df_fpath = f\"{input_path}{ligand_df_fname}\"\n",
    "nci_fpath = f\"{input_path}{nci_fname}\"\n",
    "p2rank = f\"bash {p2rank_path}\"\n",
    "\n",
    "# Loading data.\n",
    "pdb_df = pd.read_csv(pdb_df_fpath, index_col=0)\n",
    "ligand_df = pd.read_csv(ligand_df_fpath, index_col=0)\n",
    "pdb_code_list = list(pdb_df[\"pdb_code\"])\n",
    "pdb_fpath_list = list(pdb_df[\"pdb_fpath\"])\n",
    "\n",
    "# Prepare output folders.\n",
    "if len(pdb_code_list) != 1:\n",
    "    cfg_singleton = False\n",
    "if cfg_distinguish_by_timestamp or (not cfg_singleton):\n",
    "    timetag = time.strftime(\"%m%d%H%M\")+\"-\"\n",
    "else:\n",
    "    timetag = \"\"\n",
    "if cfg_singleton:\n",
    "    main_path = f\"{output_path}{timetag}{pdb_code_list[0]}/\"\n",
    "else:\n",
    "    main_path = f\"{output_path}{timetag}MultiProteins/\"\n",
    "os.system(f\"rm -rf {main_path}\")   \n",
    "os.system(f\"mkdir -p {main_path}\")\n",
    "os.system(f\"rm -rf {main_path}/p2rank\")\n",
    "os.system(f\"mkdir -p {main_path}/p2rank\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0912a7b9",
   "metadata": {},
   "source": [
    "### Show Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cff660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs :\n",
      "    main_path : ./Outputs/Dev/08040750-MultiProteins/\n",
      "    pdb_df_fname : dev.pdbs.csv\n",
      "    pdb_path : ./Inputs/Dev/RenamedPDBBind/\n",
      "    ligand_df_fname : dev.ligands.csv\n",
      "    ligand_path : ./Inputs/Dev/RenamedPDBBind/\n",
      "    p2rank_path : ../p2rank_2.3/prank\n",
      "    pdb_list : ['1g35']\n",
      "    cfg_development : True\n",
      "    cfg_use_nci : True\n",
      "    cfg_singleton : False\n",
      "    cfg_distinguish_by_timestamp : True\n"
     ]
    }
   ],
   "source": [
    "configs = {\"main_path\": main_path, \"pdb_df_fname\": pdb_df_fname, \"pdb_path\": pdb_path, \n",
    "           \"ligand_df_fname\": ligand_df_fname,\n",
    "           \"ligand_path\": ligand_path, \"p2rank_path\": p2rank_path, \n",
    "           \"pdb_list\": pdb_code_list, \n",
    "           \"cfg_development\": cfg_development, \"cfg_use_nci\": cfg_use_nci, \n",
    "           \"cfg_singleton\": cfg_singleton, \n",
    "           \"cfg_distinguish_by_timestamp\": cfg_distinguish_by_timestamp}\n",
    "print(\"Configs :\")\n",
    "for _key in configs.keys():\n",
    "    print(\"    \"+_key+\" : \"+str(configs[_key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62774b42",
   "metadata": {},
   "source": [
    "## Running!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb78b71",
   "metadata": {},
   "source": [
    "### Get protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7594d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sx_feature_utils import sx_get_protein_feature, get_clean_res_list\n",
    "from Bio.PDB import PDBParser\n",
    "def get_full_id(full_id_ls: list):\n",
    "    chain_id = full_id_ls[2]\n",
    "    res_id = full_id_ls[3][1]\n",
    "    return chain_id + \"_\" + str(res_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6acf4ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDBParser(QUIET=True)\n",
    "protein_dict = {}\n",
    "protein_res_full_id_dict = {}\n",
    "for _pname, _fpath in zip (pdb_code_list, pdb_fpath_list):\n",
    "    s = parser.get_structure(_pname, _fpath)\n",
    "    res_list = list(s.get_residues())\n",
    "    clean_res_list = get_clean_res_list(res_list, ensure_ca_exist=True)\n",
    "    clean_res_full_id_list = [get_full_id(x.full_id) for x in clean_res_list]\n",
    "    protein_dict[_pname], protein_res_full_id_dict[_pname] = sx_get_protein_feature(clean_res_list, clean_res_full_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ef2ed",
   "metadata": {},
   "source": [
    "### Segmentation of proteins by p2rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdf01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = f\"{main_path}/protein_list.ds\"\n",
    "with open(ds, \"w\") as out:\n",
    "    for _fpath in pdb_fpath_list:\n",
    "        out.write(f\"{ds_path}{_fpath}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2054fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      " P2Rank 2.3\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "predicting pockets for proteins from dataset [protein_list.ds]\n",
      "processing [1g35_protein.pdb] (1/1)\n",
      "predicting pockets finished in 0 hours 0 minutes 12.320 seconds\n",
      "results saved to directory [/home/jovyan/TankBind/nciyes/Outputs/Dev/08040750-MultiProteins/p2rank]\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      " finished successfully in 0 hours 0 minutes 13.254 seconds\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"{p2rank} predict {ds} -o {main_path}/p2rank -threads 1\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ce0876",
   "metadata": {},
   "source": [
    "### Get ligand infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d67dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from feature_utils import get_canonical_smiles\n",
    "from tqdm import tqdm\n",
    "\n",
    "ligand_name_list = list(ligand_df[\"ligand_name\"])\n",
    "ligand_pdb_list = list(ligand_df[\"pdb_code\"])\n",
    "ligand_fpath_list = list(ligand_df[\"ligand_fpath\"])\n",
    "\n",
    "canonique_smiles = []\n",
    "for _fpath in ligand_fpath_list:\n",
    "    canonique_smiles.append(get_canonical_smiles(Chem.MolToSmiles(Chem.MolFromMol2File(_fpath))))\n",
    "ligand_df[\"canonique_smiles\"] = canonique_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5671fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 178.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ligand_name</th>\n",
       "      <th>pdb_code</th>\n",
       "      <th>canonique_smiles</th>\n",
       "      <th>ligand_fpath</th>\n",
       "      <th>ligand_ftype</th>\n",
       "      <th>pocket_name</th>\n",
       "      <th>pocket_com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHF</td>\n",
       "      <td>1g35</td>\n",
       "      <td>COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...</td>\n",
       "      <td>./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2</td>\n",
       "      <td>.mol2</td>\n",
       "      <td>pocket_1</td>\n",
       "      <td>12.492,23.016,5.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHF</td>\n",
       "      <td>1g35</td>\n",
       "      <td>COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...</td>\n",
       "      <td>./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2</td>\n",
       "      <td>.mol2</td>\n",
       "      <td>pocket_2</td>\n",
       "      <td>26.141,16.353,-7.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHF</td>\n",
       "      <td>1g35</td>\n",
       "      <td>COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...</td>\n",
       "      <td>./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2</td>\n",
       "      <td>.mol2</td>\n",
       "      <td>pocket_3</td>\n",
       "      <td>7.319,39.411,11.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHF</td>\n",
       "      <td>1g35</td>\n",
       "      <td>COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...</td>\n",
       "      <td>./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2</td>\n",
       "      <td>.mol2</td>\n",
       "      <td>pocket_4</td>\n",
       "      <td>15.226,34.484,-10.408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ligand_name pdb_code                                   canonique_smiles  \\\n",
       "0         AHF     1g35  COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...   \n",
       "1         AHF     1g35  COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...   \n",
       "2         AHF     1g35  COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...   \n",
       "3         AHF     1g35  COC(=O)c1ccc(CN2[C@H](COc3ccccc3)[C@H](O)[C@@H...   \n",
       "\n",
       "                                       ligand_fpath ligand_ftype pocket_name  \\\n",
       "0  ./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2        .mol2    pocket_1   \n",
       "1  ./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2        .mol2    pocket_2   \n",
       "2  ./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2        .mol2    pocket_3   \n",
       "3  ./Inputs/Dev/RenamedPDBBind/1g35_ligand_AHF.mol2        .mol2    pocket_4   \n",
       "\n",
       "              pocket_com  \n",
       "0    12.492,23.016,5.769  \n",
       "1   26.141,16.353,-7.039  \n",
       "2    7.319,39.411,11.192  \n",
       "3  15.226,34.484,-10.408  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = []\n",
    "for i,line in tqdm(ligand_df.iterrows(), total=ligand_df.shape[0]):\n",
    "    ligand_name = line[\"ligand_name\"]\n",
    "    pdb_code = line[\"pdb_code\"]\n",
    "    pdb_fname = line[\"pdb_code\"] + \"_protein\"\n",
    "    canonique_smiles = line[\"canonique_smiles\"]\n",
    "    ligand_fpath = line[\"ligand_fpath\"]\n",
    "    ligand_ftype = os.path.splitext(os.path.split(ligand_fpath)[1])[1]\n",
    "    \n",
    "    p2rankFile = f\"{main_path}p2rank/{pdb_fname}.pdb_predictions.csv\"\n",
    "    pocket_df = pd.read_csv(p2rankFile)\n",
    "    pocket_df.columns = pocket_df.columns.str.strip()\n",
    "    pocket_coms = pocket_df[[\"center_x\", \"center_y\", \"center_z\"]].values\n",
    "    for ith_pocket, com in enumerate(pocket_coms):\n",
    "        com = \",\".join([str(a.round(3)) for a in com])\n",
    "        info.append([ligand_name, pdb_code, canonique_smiles, ligand_fpath, ligand_ftype, f\"pocket_{ith_pocket+1}\", com])\n",
    "info = pd.DataFrame(info, columns = [\"ligand_name\", \"pdb_code\", \"canonique_smiles\", \n",
    "                                     \"ligand_fpath\", \"ligand_ftype\", \"pocket_name\", \"pocket_com\"])\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d21cf",
   "metadata": {},
   "source": [
    "### Construct dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d309e3",
   "metadata": {},
   "source": [
    "#### <i>Prepare nci dataframe (will be moved to sx.nciyes.process.ipynb)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78cb542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nci_df=pd.read_csv(nci_fpath, index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff848be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from torch_geometric.data import Dataset\n",
    "from sx_utils import sx_construct_data_from_graph_gvp\n",
    "import rdkit.Chem as Chem    # conda install rdkit -c rdkit if import failure.\n",
    "from feature_utils import extract_torchdrug_feature_from_mol\n",
    "from sx_feature_utils import sx_extract_torchdrug_feature_from_mol\n",
    "from sx_new_utils import sx_ligand_dedocking\n",
    "from sx_new_utils import sx_get_nci_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fb156",
   "metadata": {},
   "source": [
    "#### <i>Definition of dataset (will be moved to definition block)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3883313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_VS(Dataset):\n",
    "    def __init__(self, root, data=None, protein_dict=None, proteinMode=0, compoundMode=1,\n",
    "                pocket_radius=20, shake_nodes=None, \n",
    "                transform=None, pre_transform=None, pre_filter=None, generate_3D_conf = False,\n",
    "                protein_res_full_id_dict=None, nci_df=None \n",
    "                ):\n",
    "        self.data = data\n",
    "        self.protein_dict = protein_dict\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        print(self.processed_paths)\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "        self.protein_dict = torch.load(self.processed_paths[1])\n",
    "        self.nci_df=nci_df\n",
    "        self.protein_res_full_id_dict = protein_res_full_id_dict\n",
    "        \n",
    "        self.proteinMode = proteinMode\n",
    "        self.pocket_radius = pocket_radius\n",
    "        self.compoundMode = compoundMode\n",
    "        self.shake_nodes = shake_nodes\n",
    "        self.generate_3D_conf = generate_3D_conf\n",
    "        #self.printflag = True\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt', 'protein.pt']\n",
    "\n",
    "    def process(self):\n",
    "        torch.save(self.data, self.processed_paths[0])\n",
    "        torch.save(self.protein_dict, self.processed_paths[1])\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        canonique_smiles = line['canonique_smiles']\n",
    "        pocket_com = line['pocket_com']\n",
    "        pocket_com = np.array(pocket_com.split(\",\")).astype(float) if type(pocket_com) == str else pocket_com\n",
    "        pocket_com = pocket_com.reshape((1, 3))\n",
    "        use_whole_protein = line['use_whole_protein'] if \"use_whole_protein\" in line.index else False\n",
    "        protein_name = line['pdb_code']\n",
    "        protein_node_xyz, protein_seq, protein_node_s, protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v = self.protein_dict[protein_name]\n",
    "        protein_res_full_id = self.protein_res_full_id_dict[protein_name]\n",
    "        ligand_fpath = line['ligand_fpath']\n",
    "        ligand_ftype = line['ligand_ftype']\n",
    "        ligand_name = line['ligand_name']\n",
    "        \n",
    "        if ligand_ftype == \".mol2\":\n",
    "            mol = Chem.MolFromMol2File(ligand_fpath)\n",
    "        elif ligand_ftype == \".mol\":\n",
    "            mol = Chem.MolFromMolFile(ligand_fpath)\n",
    "        # mol dedocking before computing features\n",
    "        mol = sx_ligand_dedocking(mol, self.generate_3D_conf)\n",
    "        mol.Compute2DCoords()  \n",
    "        coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = sx_extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)\n",
    "        '''\n",
    "        except:\n",
    "            print(f\"something wrong with {ligand_name} (pair_id:{pair_id}, smiles: {canonique_smiles}), to prevent this stops our screening, we repalce it with a placeholder smiles 'CCC'\")\n",
    "            canonique_smiles = 'CCC'\n",
    "            mol = Chem.MolFromSmiles(canonique_smiles)\n",
    "            mol.Compute2DCoords()\n",
    "            coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list, pair_dis_distribution = sx_extract_torchdrug_feature_from_mol(mol, has_LAS_mask=True)\n",
    "        '''\n",
    "        # y is distance map, instead of contact map.\n",
    "        data, input_node_list, keepNode = sx_construct_data_from_graph_gvp(protein_node_xyz, protein_seq, protein_node_s, \n",
    "                              protein_node_v, protein_edge_index, protein_edge_s, protein_edge_v,\n",
    "                              coords, compound_node_features, input_atom_edge_list, input_atom_edge_attr_list,\n",
    "                              pocket_radius=self.pocket_radius, use_whole_protein=use_whole_protein, includeDisMap=True,\n",
    "                              use_compound_com_as_pocket=False, chosen_pocket_com=pocket_com, compoundMode=self.compoundMode)\n",
    "        data.compound_pair = pair_dis_distribution.reshape(-1, 16)\n",
    "        res_full_id = [_full_id for (_full_id, _keep) in zip(protein_res_full_id, keepNode) if _keep]\n",
    "        atom_names = [_atom.GetPropsAsDict()[\"_TriposAtomName\"] for _atom in mol.GetAtoms()]\n",
    "        data.nci_matrix = sx_get_nci_matrix(protein_name, ligand_name, res_full_id, atom_names, self.nci_df)\n",
    "        \n",
    "        #data.nci_matrix = get_nci_infos(protein_name, ligand_name, pair_id)\n",
    "        print(data)\n",
    "        #print(\"NCINums\", np.sum(data.nci_matrix))\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f329c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Outputs/Dev/08040750-MultiProteins/dataset/processed/data.pt', 'Outputs/Dev/08040750-MultiProteins/dataset/processed/protein.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './Outputs/Dev/08040750-MultiProteins//dataset/': No such file or directory\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"{main_path}/dataset/\"\n",
    "os.system(f\"rm -r {dataset_path}\")\n",
    "os.system(f\"mkdir -p {dataset_path}\")\n",
    "dataset = MyDataset_VS(dataset_path, data=info, protein_dict=protein_dict, protein_res_full_id_dict=protein_res_full_id_dict, nci_df=nci_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814e362",
   "metadata": {},
   "source": [
    "### Now its turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9c40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Outputs/Dev/08040750-MultiProteins/dataset/processed/data.pt', 'Outputs/Dev/08040750-MultiProteins/dataset/processed/protein.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from torch_geometric.loader import DataLoader\n",
    "from tqdm import tqdm    # pip install tqdm if fails.\n",
    "from model import get_model\n",
    "\n",
    "dataset_path = f\"{main_path}/dataset/\"\n",
    "os.system(f\"rm -r {dataset_path}\")\n",
    "os.system(f\"mkdir -p {dataset_path}\")\n",
    "dataset = MyDataset_VS(dataset_path, data=info, protein_dict=protein_dict, protein_res_full_id_dict=protein_res_full_id_dict, nci_df=nci_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f66a00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:50:32   5 stack, readout2, pred dis map add self attention and GVP embed, compound model GIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  dis_map=[6110],\n",
      "  node_xyz=[130, 3],\n",
      "  coords=[47, 3],\n",
      "  y=[6110],\n",
      "  seq=[130],\n",
      "  compound_pair=[2209, 16],\n",
      "  nci_matrix=[130, 47],\n",
      "  \u001b[1mprotein\u001b[0m={\n",
      "    node_s=[130, 6],\n",
      "    node_v=[130, 3, 3]\n",
      "  },\n",
      "  \u001b[1mcompound\u001b[0m={ x=[47, 56] },\n",
      "  \u001b[1m(protein, p2p, protein)\u001b[0m={\n",
      "    edge_index=[2, 3310],\n",
      "    edge_s=[3310, 32],\n",
      "    edge_v=[3310, 1, 3]\n",
      "  },\n",
      "  \u001b[1m(compound, c2c, compound)\u001b[0m={\n",
      "    edge_index=[2, 102],\n",
      "    edge_weight=[102],\n",
      "    edge_attr=[102, 19]\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  dis_map=[3901],\n",
      "  node_xyz=[83, 3],\n",
      "  coords=[47, 3],\n",
      "  y=[3901],\n",
      "  seq=[83],\n",
      "  compound_pair=[2209, 16],\n",
      "  nci_matrix=[83, 47],\n",
      "  \u001b[1mprotein\u001b[0m={\n",
      "    node_s=[83, 6],\n",
      "    node_v=[83, 3, 3]\n",
      "  },\n",
      "  \u001b[1mcompound\u001b[0m={ x=[47, 56] },\n",
      "  \u001b[1m(protein, p2p, protein)\u001b[0m={\n",
      "    edge_index=[2, 2076],\n",
      "    edge_s=[2076, 32],\n",
      "    edge_v=[2076, 1, 3]\n",
      "  },\n",
      "  \u001b[1m(compound, c2c, compound)\u001b[0m={\n",
      "    edge_index=[2, 102],\n",
      "    edge_weight=[102],\n",
      "    edge_attr=[102, 19]\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  dis_map=[4324],\n",
      "  node_xyz=[92, 3],\n",
      "  coords=[47, 3],\n",
      "  y=[4324],\n",
      "  seq=[92],\n",
      "  compound_pair=[2209, 16],\n",
      "  nci_matrix=[92, 47],\n",
      "  \u001b[1mprotein\u001b[0m={\n",
      "    node_s=[92, 6],\n",
      "    node_v=[92, 3, 3]\n",
      "  },\n",
      "  \u001b[1mcompound\u001b[0m={ x=[47, 56] },\n",
      "  \u001b[1m(protein, p2p, protein)\u001b[0m={\n",
      "    edge_index=[2, 2327],\n",
      "    edge_s=[2327, 32],\n",
      "    edge_v=[2327, 1, 3]\n",
      "  },\n",
      "  \u001b[1m(compound, c2c, compound)\u001b[0m={\n",
      "    edge_index=[2, 102],\n",
      "    edge_weight=[102],\n",
      "    edge_attr=[102, 19]\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  dis_map=[3901],\n",
      "  node_xyz=[83, 3],\n",
      "  coords=[47, 3],\n",
      "  y=[3901],\n",
      "  seq=[83],\n",
      "  compound_pair=[2209, 16],\n",
      "  nci_matrix=[83, 47],\n",
      "  \u001b[1mprotein\u001b[0m={\n",
      "    node_s=[83, 6],\n",
      "    node_v=[83, 3, 3]\n",
      "  },\n",
      "  \u001b[1mcompound\u001b[0m={ x=[47, 56] },\n",
      "  \u001b[1m(protein, p2p, protein)\u001b[0m={\n",
      "    edge_index=[2, 2011],\n",
      "    edge_s=[2011, 32],\n",
      "    edge_v=[2011, 1, 3]\n",
      "  },\n",
      "  \u001b[1m(compound, c2c, compound)\u001b[0m={\n",
      "    edge_index=[2, 102],\n",
      "    edge_weight=[102],\n",
      "    edge_attr=[102, 19]\n",
      "  }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zzzzsdgesfgaersghsdrghaerdsgegsredgasdhsdfgs efhad torch.Size([4, 130, 47, 128])\n",
      "fadsldgkdq;sjaf ]]]]]] 0 <class 'numpy.ndarray'>\n",
      "ldsjvzsdjga (130, 47)\n",
      "fadsldgkdq;sjaf ]]]]]] 1 <class 'numpy.ndarray'>\n",
      "ldsjvzsdjga (83, 47)\n",
      "fadsldgkdq;sjaf ]]]]]] 2 <class 'numpy.ndarray'>\n",
      "ldsjvzsdjga (92, 47)\n",
      "fadsldgkdq;sjaf ]]]]]] 3 <class 'numpy.ndarray'>\n",
      "ldsjvzsdjga (83, 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bias_list = []\n",
    "batched_energy_list = []\n",
    "\n",
    "batch_size = 13\n",
    "device = 'cuda:4' if torch.cuda.is_available() else 'cpu'\n",
    "# device= 'cpu'\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = get_model(0, logging, device)\n",
    "# modelFile = \"../saved_models/re_dock.pt\"\n",
    "# self-dock model\n",
    "modelFile = \"../saved_models/self_dock.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(modelFile, map_location=device))\n",
    "_ = model.eval()\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=8)\n",
    "affinity_pred_list = []\n",
    "y_pred_list = []\n",
    "for data in tqdm(data_loader):\n",
    "    data = data.to(device)\n",
    "    y_pred, affinity_pred = model(data)\n",
    "    affinity_pred_list.append(affinity_pred.detach().cpu())\n",
    "    if False:\n",
    "        # we don't need to save the predicted distance map in HTVS setting.\n",
    "        for i in range(data.y_batch.max() + 1):\n",
    "            y_pred_list.append((y_pred[data['y_batch'] == i]).detach().cpu())\n",
    "affinity_pred_list = torch.cat(affinity_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507d77f2-e586-4ea6-9dad-05f52b2879ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dataset.data\n",
    "info['affinity'] = affinity_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb24d35-94d7-42c5-8146-04c125a05ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'protein_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/TankBind/nciyes/sx.nciyes.main.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e4349594553227d/home/jovyan/TankBind/nciyes/sx.nciyes.main.ipynb#ch0000035vscode-remote?line=0'>1</a>\u001b[0m chosen \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mloc[info\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mprotein_name\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msmiles\u001b[39;49m\u001b[39m'\u001b[39;49m],sort\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m'\u001b[39m\u001b[39maffinity\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg(\u001b[39m'\u001b[39m\u001b[39midxmax\u001b[39m\u001b[39m'\u001b[39m)]\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e4349594553227d/home/jovyan/TankBind/nciyes/sx.nciyes.main.ipynb#ch0000035vscode-remote?line=1'>2</a>\u001b[0m chosen\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpre\u001b[39m}\u001b[39;00m\u001b[39m/TBAff_\u001b[39m\u001b[39m{\u001b[39;00mtarget_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mpdb_code\u001b[39m}\u001b[39;00m\u001b[39m_TBChosen.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/core/frame.py:7712\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7707\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7709\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7710\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7711\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7712\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   7713\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   7714\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   7715\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   7716\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   7717\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   7718\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   7719\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   7720\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7721\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   7722\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   7723\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    883\u001b[0m         obj,\n\u001b[1;32m    884\u001b[0m         keys,\n\u001b[1;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[1;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'protein_name'"
     ]
    }
   ],
   "source": [
    "chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['affinity'].agg('idxmax')].reset_index()\n",
    "chosen.to_csv(f\"{pre}/TBAff_{target_name}_{pdb_code}_TBChosen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8c094-7684-43cd-ab43-6a5bf5492064",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv(f\"{pre}/result_info.csv\")\n",
    "if given_pocket:\n",
    "    info_right_pocket = info[info[\"pocket_name\"]==right_pocket]\n",
    "    info_right_pocket.to_csv(f\"{pre}/result_info_rightpocket.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac562f1-cd47-462b-907d-cd7d81f5e60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736b5a32-e25b-494b-a3e6-e8c97c60b964",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Related-Atoms Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcc096-ee39-4c51-8aed-afe7b9f37442",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_related = False\n",
    "if use_related:\n",
    "    energy_list = []\n",
    "    for _batch in batched_energy_list:\n",
    "        for item in _batch:\n",
    "            energy_list.append(item)\n",
    "            \n",
    "    related_atoms_list = []\n",
    "    num_atoms_list = []\n",
    "    for p in info.iterrows():\n",
    "        sm = p[1][\"smiles\"]\n",
    "        #print(sm)\n",
    "        smiles = get_canonical_smiles(sm)\n",
    "        #print(smiles)\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "        related = []\n",
    "        for _atom in mol.GetAtoms():\n",
    "            if _atom.GetAtomicNum() in [7, 8]:\n",
    "                related.append(_atom.GetIdx())\n",
    "        related_atoms_list.append(related)\n",
    "        num_atoms_list.append(mol.GetNumHeavyAtoms())\n",
    "    \n",
    "    colsum_energy_list = [i.sum(axis=0) for i in energy_list]\n",
    "    related_energy_list = [colsum_energy_list[i][related_atoms_list[i]].sum() for i in range(len(colsum_energy_list))]\n",
    "    total_energy_list = [i.sum() for i in energy_list]\n",
    "\n",
    "    related_energy_tensor = torch.tensor(related_energy_list)\n",
    "    total_energy_tensor = torch.tensor(total_energy_list)\n",
    "    nonrelated_energy_tensor = total_energy_tensor - related_energy_tensor\n",
    "\n",
    "    bias = bias_list[0]\n",
    "    outleaky = torch.nn.LeakyReLU()\n",
    "\n",
    "    related_affinity = outleaky(bias + related_energy_tensor)\n",
    "    nonrelated_affinity = outleaky(bias + nonrelated_energy_tensor)\n",
    "    \n",
    "    info['related_affinity'] = related_affinity\n",
    "    info['nonrelated_affinity'] = nonrelated_affinity\n",
    "    \n",
    "    related_chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['related_affinity'].agg('idxmax')].reset_index()\n",
    "    nonrelated_chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['nonrelated_affinity'].agg('idxmax')].reset_index()\n",
    "    related_chosen.to_csv(f\"{pre}/result_chosen_related.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56077dc-6659-4662-be95-4ccfed2c1d91",
   "metadata": {},
   "source": [
    "# 以下暂时不用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20328763",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [104]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m one_data \u001b[38;5;241m=\u001b[39m dataset[idx]\n\u001b[1;32m      8\u001b[0m data_with_batch_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(DataLoader(dataset[idx:idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m      9\u001b[0m                          follow_batch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound_pair\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 10\u001b[0m y_pred, affinity_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_with_batch_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m coords \u001b[38;5;241m=\u001b[39m one_data\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m protein_nodes_xyz \u001b[38;5;241m=\u001b[39m one_data\u001b[38;5;241m.\u001b[39mnode_xyz\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jovyan/TankBind/examples/../tankbind/model.py:349\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m    350\u001b[0m     mylogs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== IMODEL START======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys:\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/jovyan/TankBind/examples/../tankbind/model.py:89\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, h_V, edge_index, h_E, seq)\u001b[0m\n\u001b[1;32m     80\u001b[0m     node_in_dim \u001b[38;5;241m=\u001b[39m (node_in_dim[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m20\u001b[39m, node_in_dim[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_v \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     83\u001b[0m     LayerNorm(node_in_dim),\n\u001b[1;32m     84\u001b[0m     GVP(node_in_dim, node_h_dim, activations\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_e \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     87\u001b[0m     LayerNorm(edge_in_dim),\n\u001b[1;32m     88\u001b[0m     GVP(edge_in_dim, edge_h_dim, activations\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m     92\u001b[0m         GVPConvLayer(node_h_dim, edge_h_dim, drop_rate\u001b[38;5;241m=\u001b[39mdrop_rate) \n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers))\n\u001b[1;32m     95\u001b[0m ns, _ \u001b[38;5;241m=\u001b[39m node_h_dim\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tankbind_py38/lib/python3.8/site-packages/torch/nn/functional.py:2183\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2177\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2178\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "from generation_utils import get_LAS_distance_constraint_mask, get_info_pred_distance, write_with_new_coords\n",
    "# pick one with affinity greater than 7.\n",
    "chosen = info.loc[info.groupby(['protein_name', 'smiles'],sort=False)['affinity'].agg('idxmax')].reset_index()\n",
    "chosen = chosen.query(\"affinity > 7\").reset_index(drop=True)\n",
    "line = chosen.iloc[0]\n",
    "idx = line['index']\n",
    "one_data = dataset[idx]\n",
    "data_with_batch_info = next(iter(DataLoader(dataset[idx:idx+1], batch_size=1, \n",
    "                         follow_batch=['x', 'y', 'compound_pair'], shuffle=False, num_workers=1)))\n",
    "y_pred, affinity_pred = model(data_with_batch_info)\n",
    "\n",
    "coords = one_data.coords.to(device)\n",
    "protein_nodes_xyz = one_data.node_xyz.to(device)\n",
    "n_compound = coords.shape[0]\n",
    "n_protein = protein_nodes_xyz.shape[0]\n",
    "y_pred = y_pred.reshape(n_protein, n_compound).to(device).detach()\n",
    "y = one_data.dis_map.reshape(n_protein, n_compound).to(device)\n",
    "compound_pair_dis_constraint = torch.cdist(coords, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0100c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = line['smiles']\n",
    "print(smiles)\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "mol.Compute2DCoords()\n",
    "LAS_distance_constraint_mask = get_LAS_distance_constraint_mask(mol).bool()\n",
    "info = get_info_pred_distance(coords, y_pred, protein_nodes_xyz, compound_pair_dis_constraint, \n",
    "                              LAS_distance_constraint_mask=LAS_distance_constraint_mask,\n",
    "                              n_repeat=1, show_progress=False)\n",
    "toFile = f'{base_pre}/one_tankbind.sdf'\n",
    "new_coords = info.sort_values(\"loss\")['coords'].iloc[0].astype(np.double)\n",
    "write_with_new_coords(mol, new_coords, toFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c604bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview   # conda install nglview -c conda-forge if import failure\n",
    "\n",
    "proteinName = \"6dlo\"\n",
    "proteinFile = f\"{base_pre}/{proteinName}.pdb\"\n",
    "view = nglview.show_file(nglview.FileStructure(proteinFile), default=False)\n",
    "view.add_representation('cartoon', selection='protein', color='white')\n",
    "\n",
    "predictedFile = f'{base_pre}/one_tankbind.sdf'\n",
    "rdkit = view.add_component(nglview.FileStructure(predictedFile), default=False)\n",
    "rdkit.add_ball_and_stick(color='red')\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "view.render_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "view._display_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b68e83-0b11-4ba3-b624-bd5ec29241ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b357a8e7-ae7c-4b45-b311-7dfef6fd225c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d894a43-d13c-420e-9f95-1c3170dffe13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f287a6-da53-4eef-977e-9ede12ca0f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tankbind_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3642610297c2db0c2e515b5d6934e6fa60bcae4d2e973dd2c51cba19538092f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
